<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"happybear1234.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="了解常用的机器学习模型，并掌握机器学习模型的建模与调参流程  相关原理线性回归模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;49480391 决策树模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;65304798 GBDT模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;45145899 XGBoost模型https:&#x2F;&#x2F;zhuanlan.zhihu.c">
<meta property="og:type" content="article">
<meta property="og:title" content="Datawhale零基础入门数据挖掘-Task4">
<meta property="og:url" content="https://happybear1234.github.io/2020/04/01/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task4/index.html">
<meta property="og:site_name" content="happybear">
<meta property="og:description" content="了解常用的机器学习模型，并掌握机器学习模型的建模与调参流程  相关原理线性回归模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;49480391 决策树模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;65304798 GBDT模型https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;45145899 XGBoost模型https:&#x2F;&#x2F;zhuanlan.zhihu.c">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/01/G8VrRI.png">
<meta property="article:published_time" content="2020-04-01T10:36:04.000Z">
<meta property="article:modified_time" content="2020-04-03T14:23:40.180Z">
<meta property="article:author" content="happybear">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/04/01/G8VrRI.png">

<link rel="canonical" href="https://happybear1234.github.io/2020/04/01/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Datawhale零基础入门数据挖掘-Task4 | happybear</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">happybear</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-主页"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-标签"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-分类"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-档案"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://happybear1234.github.io/2020/04/01/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="happybear">
      <meta itemprop="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="happybear">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Datawhale零基础入门数据挖掘-Task4
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-04-01 18:36:04" itemprop="dateCreated datePublished" datetime="2020-04-01T18:36:04+08:00">2020-04-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-03 22:23:40" itemprop="dateModified" datetime="2020-04-03T22:23:40+08:00">2020-04-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8F%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">数据挖掘及机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-users"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="firestore-visitors-count"></span>
            </span>
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>15k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>13 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <ul>
<li>了解常用的机器学习模型，并掌握机器学习模型的建模与调参流程</li>
</ul>
<h1 id="相关原理"><a href="#相关原理" class="headerlink" title="相关原理"></a>相关原理</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><p><a href="https://zhuanlan.zhihu.com/p/49480391" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/49480391</a></p>
<h2 id="决策树模型"><a href="#决策树模型" class="headerlink" title="决策树模型"></a>决策树模型</h2><p><a href="https://zhuanlan.zhihu.com/p/65304798" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/65304798</a></p>
<h2 id="GBDT模型"><a href="#GBDT模型" class="headerlink" title="GBDT模型"></a>GBDT模型</h2><p><a href="https://zhuanlan.zhihu.com/p/45145899" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/45145899</a></p>
<h2 id="XGBoost模型"><a href="#XGBoost模型" class="headerlink" title="XGBoost模型"></a>XGBoost模型</h2><p><a href="https://zhuanlan.zhihu.com/p/86816771" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/86816771</a></p>
<h2 id="LightGBM模型"><a href="#LightGBM模型" class="headerlink" title="LightGBM模型"></a>LightGBM模型</h2><p><a href="https://zhuanlan.zhihu.com/p/89360721" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/89360721</a></p>
<h2 id="教材推荐"><a href="#教材推荐" class="headerlink" title="教材推荐"></a>教材推荐</h2><ul>
<li>《机器学习》 <a href="https://book.douban.com/subject/26708119/" target="_blank" rel="noopener">https://book.douban.com/subject/26708119/</a></li>
<li>《统计学习方法》 <a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">https://book.douban.com/subject/10590856/</a></li>
<li>《Python大战机器学习》 <a href="https://book.douban.com/subject/26987890/" target="_blank" rel="noopener">https://book.douban.com/subject/26987890/</a></li>
<li>《面向机器学习的特征工程》 <a href="https://book.douban.com/subject/26826639/" target="_blank" rel="noopener">https://book.douban.com/subject/26826639/</a></li>
<li>《数据科学家访谈录》 <a href="https://book.douban.com/subject/30129410/" target="_blank" rel="noopener">https://book.douban.com/subject/30129410/</a></li>
</ul>
<h1 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># reduce_mem_usage 函数通过调整数据类型，帮助我们减少数据在内存中占用的空间</span><br><span class="line">def reduce_mem_usage(df):</span><br><span class="line">    &quot;&quot;&quot; iterate through all the columns of a dataframe and modify the data type</span><br><span class="line">        to reduce memory usage.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    start_mem &#x3D; df.memory_usage().sum()</span><br><span class="line">    print(&#39;Memory usage of dataframe is &#123;:.2f&#125; MB&#39;.format(start_mem))</span><br><span class="line"></span><br><span class="line">    for col in df.columns:</span><br><span class="line">        col_type &#x3D; df[col].dtype</span><br><span class="line"></span><br><span class="line">        if col_type !&#x3D; object:</span><br><span class="line">            c_min &#x3D; df[col].min()</span><br><span class="line">            c_max &#x3D; df[col].max()</span><br><span class="line">            if str(col_type)[:3] &#x3D;&#x3D; &#39;int&#39;:</span><br><span class="line">                if c_min &gt; np.iinfo(np.int8).min and c_max &lt; np.iinfo(np.int8).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.int8)</span><br><span class="line">                elif c_min &gt; np.iinfo(np.int16).min and c_max &lt; np.iinfo(np.int16).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.int16)</span><br><span class="line">                elif c_min &gt; np.iinfo(np.int32).min and c_max &lt; np.iinfo(np.int32).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.int32)</span><br><span class="line">                elif c_min &gt; np.iinfo(np.int64).min and c_max &lt; np.iinfo(np.int64).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.int64)</span><br><span class="line">            else:</span><br><span class="line">                if c_min &gt; np.finfo(np.float16).min and c_max &lt; np.finfo(np.float16).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.float16)</span><br><span class="line">                elif c_min &gt; np.finfo(np.float32).min and c_max &lt; np.finfo(np.float32).max:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.float32)</span><br><span class="line">                else:</span><br><span class="line">                    df[col] &#x3D; df[col].astype(np.float64)</span><br><span class="line">        else:</span><br><span class="line">            df[col] &#x3D; df[col].astype(&#39;category&#39;)</span><br><span class="line"></span><br><span class="line">    end_mem &#x3D; df.memory_usage().sum()</span><br><span class="line">    print(&#39;Memory usage after optimization is: &#123;:.2f&#125; MB&#39;.format(end_mem))</span><br><span class="line">    print(&#39;Decreased by &#123;:.1f&#125;%&#39;.format(100 * (start_mem - end_mem) &#x2F; start_mem))</span><br><span class="line">    return df</span><br><span class="line"></span><br><span class="line">sample_feature &#x3D; reduce_mem_usage(pd.read_csv(&quot;data_for_tree.csv&quot;))</span><br></pre></td></tr></table></figure>

<pre><code>Memory usage of dataframe is 62099672.00 MB
Memory usage after optimization is: 16520303.00 MB
Decreased by 73.4%</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 返回 x in sample_feature.columns not include [&#39;price&#39;,&#39;brand&#39;,&#39;model&#39;,&#39;brand&#39;] 的列表</span><br><span class="line">continuous_feature_names &#x3D; [x for x in sample_feature.columns if x not in [&#39;price&#39;,&#39;brand&#39;,&#39;model&#39;,&#39;brand&#39;]]</span><br></pre></td></tr></table></figure>

<h1 id="线性回归-amp-五折交叉验证-amp-模拟真实业务情况"><a href="#线性回归-amp-五折交叉验证-amp-模拟真实业务情况" class="headerlink" title="线性回归 &amp; 五折交叉验证 &amp; 模拟真实业务情况"></a>线性回归 &amp; 五折交叉验证 &amp; 模拟真实业务情况</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sample_feature &#x3D; sample_feature.dropna().replace(&#39;-&#39;, 0).reset_index(drop&#x3D;True)</span><br><span class="line">sample_feature[&#39;notRepairedDamage&#39;] &#x3D; sample_feature[&#39;notRepairedDamage&#39;].astype(np.float32)</span><br><span class="line">train &#x3D; sample_feature[continuous_feature_names + [&#39;price&#39;]]</span><br><span class="line"></span><br><span class="line">train_X &#x3D; train[continuous_feature_names]</span><br><span class="line">train_y &#x3D; train[&#39;price&#39;]</span><br><span class="line">&#96;</span><br></pre></td></tr></table></figure>

<h2 id="简单建模"><a href="#简单建模" class="headerlink" title="简单建模"></a>简单建模</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">model &#x3D; LinearRegression(normalize&#x3D;True)</span><br><span class="line"></span><br><span class="line">model &#x3D; model.fit(train_X, train_y)</span><br><span class="line"></span><br><span class="line"># 查看训练的线性回归模型的截距（intercept）与权重(coef)</span><br><span class="line">print(&#39;intercept:&#39;+ str(model.intercept_))</span><br><span class="line"></span><br><span class="line">print(sorted(dict(zip(continuous_feature_names, model.coef_)).items(), key&#x3D;lambda x:x[1], reverse&#x3D;True))</span><br></pre></td></tr></table></figure>

<pre><code>intercept:-110670.68277241504

[(&apos;v_6&apos;, 3367064.3416418717), 
(&apos;v_8&apos;, 700675.5609398251),
 (&apos;v_9&apos;, 170630.27723215616), 
(&apos;v_7&apos;, 32322.661931980558), 
(&apos;v_12&apos;, 20473.670796988994), 
(&apos;v_3&apos;, 17868.07954151303), 
(&apos;v_11&apos;, 11474.9389967116), 
(&apos;v_13&apos;, 11261.764560019501), 
(&apos;v_10&apos;, 2683.9200906064084), 
(&apos;gearbox&apos;, 881.8225039250154), 
(&apos;fuelType&apos;, 363.9042507216036), 
(&apos;bodyType&apos;, 189.60271012073036), 
(&apos;city&apos;, 44.94975120522736), 
(&apos;power&apos;, 28.553901616752857), 
(&apos;brand_price_median&apos;, 0.5103728134078609), 
(&apos;brand_price_std&apos;, 0.4503634709263256), 
(&apos;brand_amount&apos;, 0.14881120395065583), 
(&apos;brand_price_max&apos;, 0.0031910186703138638), 
(&apos;SaleID&apos;, 5.355989919860593e-05), 
(&apos;offerType&apos;, 4.397239536046982e-06), 
(&apos;train&apos;, 2.7939677238464355e-07), 
(&apos;seller&apos;, -2.873130142688751e-07), 
(&apos;brand_price_sum&apos;, -2.175006868187596e-05), 
(&apos;name&apos;, -0.0002980012713074109), 
(&apos;used_time&apos;, -0.002515894332880479), 
(&apos;brand_price_average&apos;, -0.404904845101148), 
(&apos;brand_price_min&apos;, -2.2467753486888244), 
(&apos;power_bin&apos;, -34.42064411727887), 
(&apos;v_14&apos;, -274.7841180777388), 
(&apos;kilometer&apos;, -372.89752666073025), 
(&apos;notRepairedDamage&apos;, -495.1903844628239), 
(&apos;v_0&apos;, -2045.0549573558887), 
(&apos;v_5&apos;, -11022.98624082137), 
(&apos;v_4&apos;, -15121.731109860013), 
(&apos;v_2&apos;, -26098.29992055148), 
(&apos;v_1&apos;, -45556.18929726381)]</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">subsample_index &#x3D; np.random.randint(low&#x3D;0, high&#x3D;len(train_y), size&#x3D;50)</span><br><span class="line">#绘制特征v_9的值与标签的散点图，图片发现模型的预测结果（蓝色点）与真实标签（黑色点）的分布差异较大，</span><br><span class="line"># 且部分预测值出现了小于0的情况，说明我们的模型存在一些问题</span><br><span class="line">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], train_y[subsample_index], color&#x3D;&#39;black&#39;)</span><br><span class="line">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], model.predict(train_X.loc[subsample_index]), color&#x3D;&#39;blue&#39;)</span><br><span class="line">plt.xlabel(&#39;v_9&#39;)</span><br><span class="line">plt.ylabel(&#39;price&#39;)</span><br><span class="line">plt.legend([&#39;True Price&#39;,&#39;Predicted Price&#39;],loc&#x3D;&#39;upper right&#39;)</span><br><span class="line">print(&#39;The predicted price is obvious different from true price&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/04/01/G8VrRI.png" alt="1"></p>
<ul>
<li>通过作图我们发现数据的标签（price）呈现长尾分布，不利于我们的建模预测。原因是很多模型都假设数据误差项符合正态分布，而长尾分布的数据违背了这一假设。参考博客：<a href="https://blog.csdn.net/Noob_daniel/article/details/76087829" target="_blank" rel="noopener">https://blog.csdn.net/Noob_daniel/article/details/76087829</a></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line">print(&#39;It is clear to see the price shows a typical exponential distribution&#39;)</span><br><span class="line">plt.figure(figsize&#x3D;(15,5))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">sns.distplot(train_y)</span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">sns.distplot(train_y[train_y &lt; np.quantile(train_y, 0.9)])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="" alt="2"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 在这里我们对标签进行了 log(x+1) 变换，使标签贴近于正态分布</span><br><span class="line">train_y_ln &#x3D; np.log(train_y + 1)</span><br><span class="line">print(&#39;The transformed price seems like normal distribution&#39;)</span><br><span class="line">plt.figure(figsize&#x3D;(15,5))</span><br><span class="line">plt.subplot(1,2,1)</span><br><span class="line">sns.distplot(train_y_ln)</span><br><span class="line">plt.subplot(1,2,2)</span><br><span class="line">sns.distplot(train_y_ln[train_y_ln &lt; np.quantile(train_y_ln, 0.9)])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="" alt="3"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; model.fit(train_X, train_y_ln)</span><br><span class="line"></span><br><span class="line">print(&#39;intercept:&#39;+ str(model.intercept_))</span><br><span class="line">sorted(dict(zip(continuous_feature_names, model.coef_)).items(), key&#x3D;lambda x:x[1], reverse&#x3D;True)</span><br></pre></td></tr></table></figure>

<pre><code>intercept:18.750748443060488

[(&apos;v_9&apos;, 8.052410408822315), 
(&apos;v_5&apos;, 5.764240780403914), 
(&apos;v_12&apos;, 1.618206098241706), 
(&apos;v_1&apos;, 1.479831064546508), 
(&apos;v_11&apos;, 1.166900417358536), 
(&apos;v_13&apos;, 0.9404706327194452), 
(&apos;v_7&apos;, 0.7137281645215736), 
(&apos;v_3&apos;, 0.6837863827349204), 
(&apos;v_0&apos;, 0.00850050520973589), 
(&apos;power_bin&apos;, 0.008497968353528977), 
(&apos;gearbox&apos;, 0.007922378343285602), 
(&apos;fuelType&apos;, 0.006684768936305926), 
(&apos;bodyType&apos;, 0.004523520651791603), 
(&apos;power&apos;, 0.0007161895389359644), 
(&apos;brand_price_min&apos;, 3.334354528992352e-05), 
(&apos;brand_amount&apos;, 2.897880289491835e-06), 
(&apos;brand_price_median&apos;, 1.2571187771074404e-06), 
(&apos;brand_price_std&apos;, 6.659170007178332e-07), 
(&apos;brand_price_max&apos;, 6.194957302457314e-07), 
(&apos;brand_price_average&apos;, 5.999348706659352e-07), 
(&apos;SaleID&apos;, 2.1194159119234957e-08), 
(&apos;seller&apos;, 1.6262902136077173e-10), 
(&apos;offerType&apos;, 1.1036149771825876e-10), 
(&apos;train&apos;, 6.707523425575346e-12), 
(&apos;brand_price_sum&apos;, -1.5126514245669237e-10), 
(&apos;name&apos;, -7.015511195846627e-08), 
(&apos;used_time&apos;, -4.122477016270915e-06), 
(&apos;city&apos;, -0.002218783709616053), 
(&apos;v_14&apos;, -0.004234189820672137), 
(&apos;kilometer&apos;, -0.013835867353556136), 
(&apos;notRepairedDamage&apos;, -0.27027942480393996), 
(&apos;v_4&apos;, -0.8315697362911634), 
(&apos;v_2&apos;, -0.9470821267759207), 
(&apos;v_10&apos;, -1.6261468392032863), 
(&apos;v_8&apos;, -40.34300817115224), 
(&apos;v_6&apos;, -238.79035497319248)]</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#再次进行可视化，发现预测结果与真实值较为接近，且未出现异常状况</span><br><span class="line">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], train_y[subsample_index], color&#x3D;&#39;black&#39;)</span><br><span class="line">plt.scatter(train_X[&#39;v_9&#39;][subsample_index], np.exp(model.predict(train_X.loc[subsample_index])), color&#x3D;&#39;blue&#39;)</span><br><span class="line">plt.xlabel(&#39;v_9&#39;)</span><br><span class="line">plt.ylabel(&#39;price&#39;)</span><br><span class="line">plt.legend([&#39;True Price&#39;,&#39;Predicted Price&#39;],loc&#x3D;&#39;upper right&#39;)</span><br><span class="line">print(&#39;The predicted price seems normal after np.log transforming&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="" alt="4"></p>
<h2 id="五折交叉验证"><a href="#五折交叉验证" class="headerlink" title="五折交叉验证"></a>五折交叉验证</h2><blockquote>
<p>在使用训练集对参数进行训练的时候，经常会发现人们通常会将一整个训练集分为三个部分（比如mnist手写训练集）。一般分为：训练集（train_set），评估集（valid_set），测试集（test_set）这三个部分。这其实是为了保证训练效果而特意设置的。其中测试集很好理解，其实就是完全不参与训练的数据，仅仅用来观测测试效果的数&gt;&gt;据。而训练集和评估集则牵涉到下面的知识了。</p>
</blockquote>
<blockquote>
<p>因为在实际的训练中，训练的结果对于训练集的拟合程度通常还是挺好的（初始条件敏感），但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。因此我们通常并不会把所有的数据集都拿来训练，而是分出一部分来（这一部分不参加训练）对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。这种思想就称为交叉验证（Cross Validation）</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">##使用线性回归模型，对未处理标签的特征数据进行五折交叉验证</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from sklearn.metrics import mean_absolute_error,  make_scorer</span><br><span class="line">def log_transfer(func):</span><br><span class="line">    def wrapper(y, yhat):</span><br><span class="line">        result &#x3D; func(np.log(y), np.nan_to_num(np.log(yhat)))</span><br><span class="line">        return result</span><br><span class="line">    return wrapper</span><br><span class="line"></span><br><span class="line">scores &#x3D; cross_val_score(model, X&#x3D;train_X, y&#x3D;train_y, verbose&#x3D;1, cv &#x3D; 5, scoring&#x3D;make_scorer(log_transfer(mean_absolute_error)))</span><br></pre></td></tr></table></figure>

<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&#39;AVG:&#39;, np.mean(scores))</span><br></pre></td></tr></table></figure>

<pre><code>AVG: 1.3658024027748357</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#使用线性回归模型，对处理过标签的特征数据进行五折交叉验证（</span><br><span class="line">scores &#x3D; cross_val_score(model, X&#x3D;train_X, y&#x3D;train_y_ln, verbose&#x3D;1, cv &#x3D; 5, scoring&#x3D;make_scorer(mean_absolute_error))</span><br></pre></td></tr></table></figure>

<pre><code>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&#39;AVG:&#39;, np.mean(scores))</span><br></pre></td></tr></table></figure>

<pre><code>AVG: 0.19325301753940502</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scores &#x3D; pd.DataFrame(scores.reshape(1,-1))</span><br><span class="line">scores.columns &#x3D; [&#39;cv&#39; + str(x) for x in range(1, 6)]</span><br><span class="line">scores.index &#x3D; [&#39;MAE&#39;]</span><br><span class="line">print(scores)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>cv1</th>
<th>cv2</th>
<th>cv3</th>
<th>cv4</th>
<th>cv5</th>
</tr>
</thead>
<tbody><tr>
<td>MAE</td>
<td>0.190792</td>
<td>0.193758</td>
<td>0.194132</td>
<td>0.191825</td>
<td>0.195758</td>
</tr>
</tbody></table>
<h2 id="模拟真实业务情况"><a href="#模拟真实业务情况" class="headerlink" title="模拟真实业务情况"></a>模拟真实业务情况</h2><blockquote>
<p>但在事实上，由于我们并不具有预知未来的能力，五折交叉验证在某些与时间相关的数据集上反而反映了不真实的情况。通过2018年的二手车价格预测2017年的二手车价格，这显然是不合理的，因此我们还可以采用时间顺序对数据集进行分隔。在本例中，我们选用靠前时间的4/5样本当作训练集，靠后时间的1/5当作验证集，最终结果与五折交叉验证差距不大</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 采用时间顺序对数据集进行分隔 选用靠前时间的4&#x2F;5样本当作训练集，靠后时间的1&#x2F;5当作验证集</span><br><span class="line">import datetime</span><br><span class="line">sample_feature &#x3D; sample_feature.reset_index(drop&#x3D;True)</span><br><span class="line">split_point &#x3D; len(sample_feature) &#x2F;&#x2F; 5 * 4 # 取整除 - 返回商的整数部分（向下取整）</span><br><span class="line"></span><br><span class="line">train &#x3D; sample_feature.loc[:split_point].dropna()</span><br><span class="line">val &#x3D; sample_feature.loc[split_point:].dropna()</span><br><span class="line"></span><br><span class="line">train_X &#x3D; train[continuous_feature_names]</span><br><span class="line">train_y_ln &#x3D; np.log(train[&#39;price&#39;] + 1)</span><br><span class="line">val_X &#x3D; val[continuous_feature_names]</span><br><span class="line">val_y_ln &#x3D; np.log(val[&#39;price&#39;] + 1)</span><br><span class="line"></span><br><span class="line">model &#x3D; model.fit(train_X, train_y_ln)</span><br><span class="line">print(mean_absolute_error(val_y_ln, model.predict(val_X)))</span><br></pre></td></tr></table></figure>

<pre><code>0.19577667229471246</code></pre><h2 id="绘制学习率曲线与验证曲线"><a href="#绘制学习率曲线与验证曲线" class="headerlink" title="绘制学习率曲线与验证曲线"></a>绘制学习率曲线与验证曲线</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># 绘制学习率曲线与验证曲线</span><br><span class="line">from sklearn.model_selection import learning_curve, validation_curve</span><br><span class="line">def plot_learning_curve(estimator, title, X, y, ylim&#x3D;None, cv&#x3D;None,n_jobs&#x3D;1, train_size&#x3D;np.linspace(.1, 1.0, 5 )):</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.title(title)</span><br><span class="line">    if ylim is not None:</span><br><span class="line">        plt.ylim(*ylim)</span><br><span class="line">    plt.xlabel(&#39;Training example&#39;)</span><br><span class="line">    plt.ylabel(&#39;score&#39;)</span><br><span class="line">    train_sizes, train_scores, test_scores &#x3D; learning_curve(estimator, X, y, cv&#x3D;cv, n_jobs&#x3D;n_jobs, train_sizes&#x3D;train_size, scoring &#x3D; make_scorer(mean_absolute_error))</span><br><span class="line">    train_scores_mean &#x3D; np.mean(train_scores, axis&#x3D;1)</span><br><span class="line">    train_scores_std &#x3D; np.std(train_scores, axis&#x3D;1)</span><br><span class="line">    test_scores_mean &#x3D; np.mean(test_scores, axis&#x3D;1)</span><br><span class="line">    test_scores_std &#x3D; np.std(test_scores, axis&#x3D;1)</span><br><span class="line">    plt.grid()#区域</span><br><span class="line"></span><br><span class="line">    # x：第一个参数表示覆盖的区域，我直接复制为x，表示整个x都覆盖</span><br><span class="line">    # 0：表示覆盖的下限</span><br><span class="line">    # y：表示覆盖的上限是y这个曲线</span><br><span class="line">    # facecolor：覆盖区域的颜色</span><br><span class="line">    # alpha：覆盖区域的透明度[0,1],其值越大，表示越不透明</span><br><span class="line">    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,</span><br><span class="line">                     train_scores_mean + train_scores_std, alpha&#x3D;0.1,</span><br><span class="line">                     color&#x3D;&quot;r&quot;)</span><br><span class="line">    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,</span><br><span class="line">                     test_scores_mean + test_scores_std, alpha&#x3D;0.1,</span><br><span class="line">                     color&#x3D;&quot;g&quot;)</span><br><span class="line">    plt.plot(train_sizes, train_scores_mean, &#39;o-&#39;, color&#x3D;&#39;r&#39;,</span><br><span class="line">             label&#x3D;&quot;Training score&quot;)</span><br><span class="line">    plt.plot(train_sizes, test_scores_mean,&#39;o-&#39;,color&#x3D;&quot;g&quot;,</span><br><span class="line">             label&#x3D;&quot;Cross-validation score&quot;)</span><br><span class="line">    plt.legend(loc&#x3D;&quot;best&quot;)</span><br><span class="line">    return plt</span><br><span class="line"></span><br><span class="line">plot_learning_curve(LinearRegression(), &#39;Liner_model&#39;, train_X[:1000], train_y_ln[:1000], ylim&#x3D;(0.0, 0.5), cv&#x3D;5, n_jobs&#x3D;1)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="" alt="5"></p>
<h1 id="多种模型对比"><a href="#多种模型对比" class="headerlink" title="多种模型对比"></a>多种模型对比</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train &#x3D; sample_feature[continuous_feature_names + [&#39;price&#39;]].dropna()</span><br><span class="line"></span><br><span class="line">train_X &#x3D; train[continuous_feature_names]</span><br><span class="line">train_y &#x3D; train[&#39;price&#39;]</span><br><span class="line">train_y_ln &#x3D; np.log(train_y + 1)</span><br></pre></td></tr></table></figure>

<h2 id="线性模型-amp-嵌入式特征选择"><a href="#线性模型-amp-嵌入式特征选择" class="headerlink" title="线性模型 &amp; 嵌入式特征选择"></a>线性模型 &amp; 嵌入式特征选择</h2><ul>
<li>本章节默认，学习者已经了解关于过拟合、模型复杂度、正则化等概念。否则请寻找相关资料或参考如下连接：</li>
</ul>
<blockquote>
<p>用简单易懂的语言描述「过拟合 overfitting」<a href="https://www.zhihu.com/question/32246256/answer/55320482" target="_blank" rel="noopener">https://www.zhihu.com/question/32246256/answer/55320482</a><br>模型复杂度与模型的泛化能力 <a href="http://yangyingming.com/article/434/" target="_blank" rel="noopener">http://yangyingming.com/article/434/</a><br>正则化的直观理解 <a href="https://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">https://blog.csdn.net/jinping_shi/article/details/52433975</a></p>
</blockquote>
<p>在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明显的分别。而嵌入式特征选择在学习器训练过程中自动地进行特征选择。嵌入式选择最常用的是L1正则化与L2正则化。在对线性回归模型加入两种正则化方法后，他们分别变成了Lasso回归与岭(Ridge)回归。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 线性模型 &amp; 嵌入式特征选择</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.linear_model import Lasso</span><br><span class="line"></span><br><span class="line">models &#x3D; [LinearRegression(),</span><br><span class="line">          Ridge(),</span><br><span class="line">          Lasso()]</span><br><span class="line"></span><br><span class="line">result &#x3D; dict()</span><br><span class="line">for model in models:</span><br><span class="line">    model_name &#x3D; str(model).split(&#39;(&#39;)[0]</span><br><span class="line">    scores &#x3D; cross_val_score(model, X&#x3D;train_X, y&#x3D;train_y_ln, verbose&#x3D;0, cv &#x3D; 5, scoring&#x3D;make_scorer(mean_absolute_error))</span><br><span class="line">    result[model_name] &#x3D; scores</span><br><span class="line">    print(model_name + &#39; is finished&#39;)</span><br></pre></td></tr></table></figure>

<pre><code>LinearRegression is finished
Ridge is finished
Lasso is finished</code></pre><ul>
<li>对三种方法的效果对比</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 对三种方法的效果对比</span><br><span class="line">result &#x3D; pd.DataFrame(result)</span><br><span class="line">result.index &#x3D; [&#39;cv&#39; + str(x) for x in range(1, 6)]</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>LinearRegression</th>
<th>Ridge</th>
<th>Lasso</th>
</tr>
</thead>
<tbody><tr>
<td>cv1</td>
<td>0.190792</td>
<td>0.194832</td>
<td>0.383899</td>
</tr>
<tr>
<td>cv2</td>
<td>0.193758</td>
<td>0.197632</td>
<td>0.381893</td>
</tr>
<tr>
<td>cv3</td>
<td>0.194132</td>
<td>0.198123</td>
<td>0.384090</td>
</tr>
<tr>
<td>cv4</td>
<td>0.191825</td>
<td>0.195670</td>
<td>0.380526</td>
</tr>
<tr>
<td>cv5</td>
<td>0.195758</td>
<td>0.199676</td>
<td>0.383611</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; LinearRegression().fit(train_X, train_y_ln)</span><br><span class="line">print(&#39;intercept:&#39;+ str(model.intercept_))</span><br><span class="line">sns.barplot(abs(model.coef_), continuous_feature_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>intercept:18.75072374836874<br><img src="" alt="6"></p>
<p>L2正则化在拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; Ridge().fit(train_X, train_y_ln)</span><br><span class="line">print(&#39;intercept:&#39;+ str(model.intercept_))</span><br><span class="line">sns.barplot(abs(model.coef_), continuous_feature_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>intercept:4.671710763117783<br><img src="" alt="7"></p>
<p>L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。如下图，我们发现power与userd_time特征非常重要</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; Lasso().fit(train_X, train_y_ln)</span><br><span class="line">print(&#39;intercept:&#39;+ str(model.intercept_))</span><br><span class="line">sns.barplot(abs(model.coef_), continuous_feature_names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>intercept:8.672182470075398<br><img src="" alt="8"></p>
<p>除此之外，决策树通过信息熵或GINI指数选择分裂节点时，优先选择的分裂特征也更加重要，这同样是一种特征选择的方法。XGBoost与LightGBM模型中的model_importance指标正是基于此计算的</p>
<h2 id="非线性模型"><a href="#非线性模型" class="headerlink" title="非线性模型"></a>非线性模型</h2>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/28/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task3/" rel="prev" title="Datawhale零基础入门数据挖掘-Task3">
      <i class="fa fa-chevron-left"></i> Datawhale零基础入门数据挖掘-Task3
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/04/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task5/" rel="next" title="Datawhale零基础入门数据挖掘-Task5">
      Datawhale零基础入门数据挖掘-Task5 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#相关原理"><span class="nav-number">1.</span> <span class="nav-text">相关原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归模型"><span class="nav-number">1.1.</span> <span class="nav-text">线性回归模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型"><span class="nav-number">1.2.</span> <span class="nav-text">决策树模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT模型"><span class="nav-number">1.3.</span> <span class="nav-text">GBDT模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XGBoost模型"><span class="nav-number">1.4.</span> <span class="nav-text">XGBoost模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LightGBM模型"><span class="nav-number">1.5.</span> <span class="nav-text">LightGBM模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#教材推荐"><span class="nav-number">1.6.</span> <span class="nav-text">教材推荐</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#读取数据"><span class="nav-number">2.</span> <span class="nav-text">读取数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归-amp-五折交叉验证-amp-模拟真实业务情况"><span class="nav-number">3.</span> <span class="nav-text">线性回归 &amp; 五折交叉验证 &amp; 模拟真实业务情况</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#简单建模"><span class="nav-number">3.1.</span> <span class="nav-text">简单建模</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五折交叉验证"><span class="nav-number">3.2.</span> <span class="nav-text">五折交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模拟真实业务情况"><span class="nav-number">3.3.</span> <span class="nav-text">模拟真实业务情况</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#绘制学习率曲线与验证曲线"><span class="nav-number">3.4.</span> <span class="nav-text">绘制学习率曲线与验证曲线</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#多种模型对比"><span class="nav-number">4.</span> <span class="nav-text">多种模型对比</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性模型-amp-嵌入式特征选择"><span class="nav-number">4.1.</span> <span class="nav-text">线性模型 &amp; 嵌入式特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#非线性模型"><span class="nav-number">4.2.</span> <span class="nav-text">非线性模型</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">happybear</p>
  <div class="site-description" itemprop="description">happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/happybear1234" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;happybear1234" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">happybear</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">96k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:27</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>




  <script src="https://www.gstatic.com/firebasejs/6.3.3/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/6.3.3/firebase-firestore.js"></script>
  <script>
    firebase.initializeApp({
      apiKey   : '',
      projectId: ''
    });

    function getCount(doc, increaseCount) {
      // IncreaseCount will be false when not in article page
      return doc.get().then(d => {
        var count = 0;
        if (!d.exists) { // Has no data, initialize count
          if (increaseCount) {
            doc.set({
              count: 1
            });
            count = 1;
          }
        } else { // Has data
          count = d.data().count;
          if (increaseCount) {
            // If first view this article
            doc.set({ // Increase count
              count: count + 1
            });
            count++;
          }
        }

        return count;
      });
    }

    function appendCountTo(el) {
      return count => {
        el.innerText = count;
      }
    }
  </script>
  <script>
    (function() {
      var db = firebase.firestore();
      var articles = db.collection('articles');

      if (CONFIG.page.isPost) { // Is article page
        var title = document.querySelector('.post-title').innerText.trim();
        var doc = articles.doc(title);
        var increaseCount = CONFIG.hostname === location.hostname;
        if (localStorage.getItem(title)) {
          increaseCount = false;
        } else {
          // Mark as visited
          localStorage.setItem(title, true);
        }
        getCount(doc, increaseCount).then(appendCountTo(document.querySelector('.firestore-visitors-count')));
      } else if (CONFIG.page.isHome) { // Is index page
        var promises = [...document.querySelectorAll('.post-title')].map(element => {
          var title = element.innerText.trim();
          var doc = articles.doc(title);
          return getCount(doc);
        });
        Promise.all(promises).then(counts => {
          var metas = document.querySelectorAll('.firestore-visitors-count');
          counts.forEach((val, idx) => {
            appendCountTo(metas[idx])(val);
          });
        });
      }
    })();
  </script>




      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'c83bf087982f58c4586a',
      clientSecret: 'ed1f6d1814cb6dec62fefd737d4f7196a7aebfb4',
      repo        : 'happybear1234-blog-comments',
      owner       : 'happybear1234',
      admin       : ['happybear1234'],
      id          : 'ba5d15b0f4d60e6dd87d39959f272fe8',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
