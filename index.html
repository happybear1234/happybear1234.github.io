<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"happybear1234.github.io","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
<meta property="og:type" content="website">
<meta property="og:title" content="happybear">
<meta property="og:url" content="https://happybear1234.github.io/index.html">
<meta property="og:site_name" content="happybear">
<meta property="og:description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="happybear">
<meta property="article:tag" content="happybear">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="C+++">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://happybear1234.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>happybear</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">happybear</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-主页"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-标签"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-分类"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-档案"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://happybear1234.github.io/2020/03/28/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="happybear">
      <meta itemprop="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="happybear">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/28/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task3/" class="post-title-link" itemprop="url">Datawhale零基础入门数据挖掘-Task3</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-03-28 17:51:42 / 修改时间：18:14:17" itemprop="dateCreated datePublished" datetime="2020-03-28T17:51:42+08:00">2020-03-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8F%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">数据挖掘及机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-users"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="firestore-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>特征工程：对于特征进行进一步分析，并对于数据进行处理</li>
</ul>
<h1 id="常见的特征工程包括"><a href="#常见的特征工程包括" class="headerlink" title="常见的特征工程包括"></a>常见的特征工程包括</h1><ol>
<li>异常处理</li>
</ol>
<ul>
<li>通过箱线图（或 3-Sigma）分析删除异常值；</li>
<li>BOX-COX 转换（处理有偏分布）；</li>
<li>长尾截断；</li>
</ul>
<ol start="2">
<li>特征归一化/标准化：</li>
</ol>
<ul>
<li>标准化（转换为标准正态分布）；</li>
<li>归一化（抓换到 [0,1] 区间）；</li>
<li>针对幂律分布，可以采用公式：$log(\frac{1+x}{1+median})$</li>
</ul>
<ol start="3">
<li>数据分桶：</li>
</ol>
<ul>
<li>等频分桶；</li>
<li>等距分桶；</li>
<li>Best-KS 分桶（类似利用基尼指数进行二分类）；</li>
<li>卡方分桶；</li>
</ul>
<ol start="4">
<li>缺失值处理：</li>
</ol>
<ul>
<li>不处理（针对类似 XGBoost 等树模型）；</li>
<li>删除（缺失数据太多）；</li>
<li>插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等；</li>
<li>分箱，缺失值一个箱；</li>
</ul>
<ol start="5">
<li>特征构造：</li>
</ol>
<ul>
<li>构造统计量特征，报告计数、求和、比例、标准差等；</li>
<li>时间特征，包括相对时间和绝对时间，节假日，双休日等；</li>
<li>地理信息，包括分箱，分布编码等方法；</li>
<li>非线性变换，包括 log/ 平方/ 根号等；</li>
<li>特征组合，特征交叉；</li>
<li>仁者见仁，智者见智。</li>
</ul>
<ol start="6">
<li>特征筛选</li>
</ol>
<ul>
<li>过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法；</li>
<li>包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ；</li>
<li>嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归；</li>
</ul>
<ol start="7">
<li>降维</li>
</ol>
<ul>
<li>PCA/ LDA/ ICA；</li>
<li>特征选择也是一种降维。</li>
</ul>
<h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from operator import itemgetter</span><br><span class="line"></span><br><span class="line">Train_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_train_20200313.csv&quot;, sep&#x3D;&quot; &quot;)</span><br><span class="line">Test_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_testA_20200313.csv&quot;, sep&#x3D;&quot; &quot;)</span><br><span class="line"></span><br><span class="line">print(Train_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(150000, 31)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.head())</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>SaleID</th>
<th>name</th>
<th>regDate</th>
<th>model</th>
<th>…</th>
<th>v_11</th>
<th>v_12</th>
<th>v_13</th>
<th>v_14</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>736</td>
<td>20040402</td>
<td>30.0</td>
<td>…</td>
<td>2.804097</td>
<td>-2.420821</td>
<td>0.795292</td>
<td>0.914762</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2262</td>
<td>20030301</td>
<td>40.0</td>
<td>…</td>
<td>2.096338</td>
<td>-1.030483</td>
<td>-1.722674</td>
<td>0.245522</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>14874</td>
<td>20040403</td>
<td>115.0</td>
<td>…</td>
<td>1.803559</td>
<td>1.565330</td>
<td>-0.832687</td>
<td>-0.229963</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>71865</td>
<td>19960908</td>
<td>109.0</td>
<td>…</td>
<td>1.285940</td>
<td>-0.501868</td>
<td>-2.438353</td>
<td>-0.478699</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>111080</td>
<td>20120103</td>
<td>110.0</td>
<td>…</td>
<td>0.910783</td>
<td>0.931110</td>
<td>2.834518</td>
<td>1.923482</td>
</tr>
</tbody></table>
<p>[5 rows x 31 columns]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.columns)</span><br></pre></td></tr></table></figure>

<pre><code>Index([&apos;SaleID&apos;, &apos;name&apos;, &apos;regDate&apos;, &apos;model&apos;, &apos;brand&apos;, &apos;bodyType&apos;, &apos;fuelType&apos;,
       &apos;gearbox&apos;, &apos;power&apos;, &apos;kilometer&apos;, &apos;notRepairedDamage&apos;, &apos;regionCode&apos;,
       &apos;seller&apos;, &apos;offerType&apos;, &apos;creatDate&apos;, &apos;price&apos;, &apos;v_0&apos;, &apos;v_1&apos;, &apos;v_2&apos;, &apos;v_3&apos;,
       &apos;v_4&apos;, &apos;v_5&apos;, &apos;v_6&apos;, &apos;v_7&apos;, &apos;v_8&apos;, &apos;v_9&apos;, &apos;v_10&apos;, &apos;v_11&apos;, &apos;v_12&apos;,
       &apos;v_13&apos;, &apos;v_14&apos;],
      dtype=&apos;object&apos;)</code></pre><h1 id="删除异常值"><a href="#删除异常值" class="headerlink" title="删除异常值"></a>删除异常值</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">## 删除异常值</span><br><span class="line"># 这里我包装了一个异常值处理的代码，可以随便调用</span><br><span class="line">def outliers_proc(data, col_name, scale&#x3D;3):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    用于清洗异常值，默认用box_plot(scale&#x3D;3)进行清洗</span><br><span class="line">    :param data:接受 pandas 数据格式</span><br><span class="line">    :param col_name:pandas 列名</span><br><span class="line">    :param scale:尺度</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def box_plot_outliers(data_ser, box_scale):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        利用箱线图去除异常值</span><br><span class="line">        :param data_ser:接收 pandas.Series 数据格式</span><br><span class="line">        :param box_scale: 箱线图尺度 （规定大于上四分位数1.5倍四分位数差 的值，或者小于下四分位数1.5倍四分位数差的值，划为异常值）</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        iqr &#x3D; box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25)) # 3倍四分位数差</span><br><span class="line">        val_low &#x3D; data_ser.quantile(0.25) - iqr # 下限&#x3D;Q1-3IQR</span><br><span class="line">        val_up &#x3D; data_ser.quantile(0.75) + iqr # 上限&#x3D;Q3+3IQR</span><br><span class="line">        rule_low &#x3D; (data_ser &lt; val_low)</span><br><span class="line">        rule_up &#x3D; (data_ser &gt; val_up) # 返回 pandas.Series 中对应值的bool</span><br><span class="line">        return (rule_low, rule_up), (val_low, val_up)</span><br><span class="line"></span><br><span class="line">    data_n &#x3D; data.copy() # copy 数据</span><br><span class="line">    data_series &#x3D; data_n[col_name] # 返回指定 col_name 数据</span><br><span class="line">    rule, value &#x3D; box_plot_outliers(data_series, box_scale&#x3D;scale)</span><br><span class="line">    index &#x3D; np.arange(data_series.shape[0])[rule[0]|rule[1]] # 返回rule_low, rule_up中为True的下标的列表</span><br><span class="line">    print(&quot;Delete number is:&#123;&#125;&quot;.format(len(index))) # 打印下标列表中个数</span><br><span class="line">    data_n &#x3D; data_n.drop(index) # 删除(删除后下标没变)</span><br><span class="line">    data_n.reset_index(drop&#x3D;True, inplace&#x3D;True) # 重置索引（drop&#x3D;True删除原来的索引;inplace&#x3D;True当前修改状态应用到原来Series中）</span><br><span class="line">    print(&quot;Now column number is:&#123;&#125;&quot;.format(data_n.shape[0])) # 查看删除后的数据个数</span><br><span class="line">    index_low &#x3D; np.arange(data_series.shape[0])[rule[0]]</span><br><span class="line">    outliers &#x3D; data_series.iloc[index_low] # ilco-按下标进行索引</span><br><span class="line">    print(&quot;Description of data larger than the lower bound is:&quot;)</span><br><span class="line">    print(pd.Series(outliers).describe())</span><br><span class="line">    index_up &#x3D; np.arange(data_series.shape[0])[rule[1]]</span><br><span class="line">    outliers &#x3D; data_series.iloc[index_up]</span><br><span class="line">    print(&quot;Description of data larger than the upper bound is:&quot;)</span><br><span class="line">    print(pd.Series(outliers).describe())</span><br><span class="line"></span><br><span class="line">    fig, ax &#x3D; plt.subplots(1, 2, figsize&#x3D;(10, 7)) # 创建子图:1行2列</span><br><span class="line">    sns.boxplot(y&#x3D;data[col_name], data&#x3D;data, palette&#x3D;&quot;Set1&quot;, ax&#x3D;ax[0]) # 箱线图</span><br><span class="line">    sns.boxplot(y&#x3D;data_n[col_name], data&#x3D;data_n, palette&#x3D;&quot;Set1&quot;, ax&#x3D;ax[1])</span><br><span class="line">    plt.show()</span><br><span class="line">    return data_n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 我们可以删掉一些异常数据,以 power 为例</span><br><span class="line">## 这里删不删可以自行判断</span><br><span class="line">## 但是注意 Test 的数据不能删</span><br><span class="line">Train_data &#x3D; outliers_proc(Train_data, &quot;power&quot;, scale&#x3D;3)</span><br></pre></td></tr></table></figure>

<pre><code>Delete number is:963
Now column number is:149037
Description of data larger than the lower bound is:
count    0.0
mean     NaN
std      NaN
min      NaN
25%      NaN
50%      NaN
75%      NaN
max      NaN
Name: power, dtype: float64
Description of data larger than the upper bound is:
count      963.000000
mean       846.836968
std       1929.418081
min        376.000000
25%        400.000000
50%        436.000000
75%        514.000000
max      19312.000000
Name: power, dtype: float64</code></pre><p><img src="https://s1.ax1x.com/2020/03/28/GAATiR.png" alt="1"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://happybear1234.github.io/2020/03/24/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="happybear">
      <meta itemprop="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="happybear">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/24/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task2/" class="post-title-link" itemprop="url">Datawhale零基础入门数据挖掘-Task2</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-24 17:27:07" itemprop="dateCreated datePublished" datetime="2020-03-24T17:27:07+08:00">2020-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-26 19:46:30" itemprop="dateModified" datetime="2020-03-26T19:46:30+08:00">2020-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8F%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">数据挖掘及机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-users"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="firestore-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>33k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>30 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>EDA的价值主要在于熟悉数据集，了解数据集，对数据集进行验证来确定所获得数据集可以用于接下来的机器学习或者深度学习使用</li>
<li>当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系</li>
<li>进行数据处理以及特征工程,使数据集的结构和特征集让接下来的预测问题更加可靠</li>
</ul>
<h1 id="载入各种数据科学以及可视化库"><a href="#载入各种数据科学以及可视化库" class="headerlink" title="载入各种数据科学以及可视化库"></a>载入各种数据科学以及可视化库</h1><h2 id="载入各种数据科学以及可视化库-1"><a href="#载入各种数据科学以及可视化库-1" class="headerlink" title="载入各种数据科学以及可视化库"></a>载入各种数据科学以及可视化库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入warnings包，利用过滤器来实现忽略警告语句</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import missingno as msno</span><br></pre></td></tr></table></figure>
<h1 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## pd.set_option(&#39;display.max_columns&#39;, None)# 显示所有列</span><br><span class="line">## pd.set_option(&#39;display.max_row&#39;, None)# 显示所有行</span><br><span class="line">## 1)载入训练集和测试集</span><br><span class="line">Train_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_train_20200313.csv&quot;, sep &#x3D; &quot; &quot;)</span><br><span class="line">Test_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_testA_20200313.csv&quot;, sep &#x3D; &quot; &quot;)</span><br></pre></td></tr></table></figure>
<ul>
<li>以下主要以Train_data为例<h2 id="简略观察数据"><a href="#简略观察数据" class="headerlink" title="简略观察数据"></a>简略观察数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 2)简略观察数据（head()+shape)</span><br><span class="line">print(Train_data.head().append(Train_data.tail()))</span><br></pre></td></tr></table></figure>

</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>SaleID</th>
<th>name</th>
<th>regDate</th>
<th>model</th>
<th>…</th>
<th>v_11</th>
<th>v_12</th>
<th>v_13</th>
<th>v_14</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>736</td>
<td>20040402</td>
<td>30.0</td>
<td>…</td>
<td>2.804097</td>
<td>-2.420821</td>
<td>0.795292</td>
<td>0.914762</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2262</td>
<td>20030301</td>
<td>40.0</td>
<td>…</td>
<td>2.096338</td>
<td>-1.030483</td>
<td>-1.722674</td>
<td>0.245522</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>14874</td>
<td>20040403</td>
<td>115.0</td>
<td>…</td>
<td>1.803559</td>
<td>1.565330</td>
<td>-0.832687</td>
<td>-0.229963</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>71865</td>
<td>19960908</td>
<td>109.0</td>
<td>…</td>
<td>1.285940</td>
<td>-0.501868</td>
<td>-2.438353</td>
<td>-0.478699</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>111080</td>
<td>20120103</td>
<td>110.0</td>
<td>…</td>
<td>0.910783</td>
<td>0.931110</td>
<td>2.834518</td>
<td>1.923482</td>
</tr>
<tr>
<td>149995</td>
<td>149995</td>
<td>163978</td>
<td>20000607</td>
<td>121.0</td>
<td>…</td>
<td>-2.983973</td>
<td>0.589167</td>
<td>-1.304370</td>
<td>-0.302592</td>
</tr>
<tr>
<td>149996</td>
<td>149996</td>
<td>184535</td>
<td>20091102</td>
<td>116.0</td>
<td>…</td>
<td>-2.774615</td>
<td>2.553994</td>
<td>0.924196</td>
<td>-0.272160</td>
</tr>
<tr>
<td>149997</td>
<td>149997</td>
<td>147587</td>
<td>20101003</td>
<td>60.0</td>
<td>…</td>
<td>-1.630677</td>
<td>2.290197</td>
<td>1.891922</td>
<td>0.414931</td>
</tr>
<tr>
<td>149998</td>
<td>149998</td>
<td>45907</td>
<td>20060312</td>
<td>34.0</td>
<td>…</td>
<td>-2.633719</td>
<td>1.414937</td>
<td>0.431981</td>
<td>-1.659014</td>
</tr>
<tr>
<td>149999</td>
<td>149999</td>
<td>177672</td>
<td>19990204</td>
<td>19.0</td>
<td>…</td>
<td>-3.179913</td>
<td>0.031724</td>
<td>-1.483350</td>
<td>-0.342674</td>
</tr>
</tbody></table>
<p>[10 rows x 31 columns]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(150000, 31)</code></pre><h1 id="总览数据概况"><a href="#总览数据概况" class="headerlink" title="总览数据概况"></a>总览数据概况</h1><ol>
<li>describe种有每列的统计量，个数count、平均值mean、方差std、最小值min、中位数25% 50% 75% 、以及最大值 看这个信息主要是瞬间掌握数据的大概的范围以及每个值的异常值的判断，比如有的时候会发现999 9999 -1 等值这些其实都是nan的另外一种表达方式，有的时候需要注意下</li>
<li>info 通过info来了解数据每列的type，有助于了解是否存在除了nan以外的特殊符号异常</li>
</ol>
<h2 id="通过describe-来熟悉相关统计量"><a href="#通过describe-来熟悉相关统计量" class="headerlink" title="通过describe()来熟悉相关统计量"></a>通过describe()来熟悉相关统计量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 3)通过describe()来熟悉相关统计量</span><br><span class="line">print(Train_data.describe())</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>SaleID</th>
<th>name</th>
<th>…</th>
<th>v_13</th>
<th>v_14</th>
</tr>
</thead>
<tbody><tr>
<td>count</td>
<td>150000.000000</td>
<td>150000.000000</td>
<td>…</td>
<td>150000.000000</td>
<td>150000.000000</td>
</tr>
<tr>
<td>mean</td>
<td>74999.500000</td>
<td>68349.172873</td>
<td>…</td>
<td>0.000313</td>
<td>-0.000688</td>
</tr>
<tr>
<td>std</td>
<td>43301.414527</td>
<td>61103.875095</td>
<td>…</td>
<td>1.288988</td>
<td>1.038685</td>
</tr>
<tr>
<td>min</td>
<td>0.000000</td>
<td>0.000000</td>
<td>…</td>
<td>-4.153899</td>
<td>-6.546556</td>
</tr>
<tr>
<td>25%</td>
<td>37499.750000</td>
<td>11156.000000</td>
<td>…</td>
<td>-1.057789</td>
<td>-0.437034</td>
</tr>
<tr>
<td>50%</td>
<td>74999.500000</td>
<td>51638.000000</td>
<td>…</td>
<td>-0.036245</td>
<td>0.141246</td>
</tr>
<tr>
<td>75%</td>
<td>112499.250000</td>
<td>118841.250000</td>
<td>…</td>
<td>0.942813</td>
<td>0.680378</td>
</tr>
<tr>
<td>max</td>
<td>149999.000000</td>
<td>196812.000000</td>
<td>…</td>
<td>11.147669</td>
<td>8.658418</td>
</tr>
</tbody></table>
<p>[8 rows x 30 columns]</p>
<h2 id="通过info-来熟悉数据类型"><a href="#通过info-来熟悉数据类型" class="headerlink" title="通过info()来熟悉数据类型"></a>通过info()来熟悉数据类型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 4)通过info()来熟悉数据类型</span><br><span class="line">print(Train_data.info())</span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 31 columns):
 #   Column             Non-Null Count   Dtype  
---  ------             --------------   -----  
 0   SaleID             150000 non-null  int64  
 1   name               150000 non-null  int64  
 2   regDate            150000 non-null  int64  
 3   model              149999 non-null  float64
 4   brand              150000 non-null  int64  
 5   bodyType           145494 non-null  float64
 6   fuelType           141320 non-null  float64
 7   gearbox            144019 non-null  float64
 8   power              150000 non-null  int64  
 9   kilometer          150000 non-null  float64
 10  notRepairedDamage  150000 non-null  object 
 11  regionCode         150000 non-null  int64  
 12  seller             150000 non-null  int64  
 13  offerType          150000 non-null  int64  
 14  creatDate          150000 non-null  int64  
 15  price              150000 non-null  int64  
 16  v_0                150000 non-null  float64
 17  v_1                150000 non-null  float64
 18  v_2                150000 non-null  float64
 19  v_3                150000 non-null  float64
 20  v_4                150000 non-null  float64
 21  v_5                150000 non-null  float64
 22  v_6                150000 non-null  float64
 23  v_7                150000 non-null  float64
 24  v_8                150000 non-null  float64
 25  v_9                150000 non-null  float64
 26  v_10               150000 non-null  float64
 27  v_11               150000 non-null  float64
 28  v_12               150000 non-null  float64
 29  v_13               150000 non-null  float64
 30  v_14               150000 non-null  float64
dtypes: float64(20), int64(10), object(1)
memory usage: 35.5+ MB
None</code></pre><h1 id="判断数据缺失和异常"><a href="#判断数据缺失和异常" class="headerlink" title="判断数据缺失和异常"></a>判断数据缺失和异常</h1><h2 id="查看每列的存在nan情况"><a href="#查看每列的存在nan情况" class="headerlink" title="查看每列的存在nan情况"></a>查看每列的存在nan情况</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 5) 查看每列的存在nan情况</span><br><span class="line">print(Train_data.isnull().sum())</span><br></pre></td></tr></table></figure>

<pre><code>SaleID                  0
name                    0
regDate                 0
model                   1
brand                   0
bodyType             4506
fuelType             8680
gearbox              5981
power                   0
kilometer               0
notRepairedDamage       0
regionCode              0
seller                  0
offerType               0
creatDate               0
price                   0
v_0                     0
v_1                     0
v_2                     0
v_3                     0
v_4                     0
v_5                     0
v_6                     0
v_7                     0
v_8                     0
v_9                     0
v_10                    0
v_11                    0
v_12                    0
v_13                    0
v_14                    0
dtype: int64</code></pre><h2 id="nan可视化"><a href="#nan可视化" class="headerlink" title="nan可视化"></a>nan可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#nan可视化</span><br><span class="line">missing &#x3D; Train_data.isnull().sum()</span><br><span class="line">missing &#x3D; missing[missing &gt; 0]</span><br><span class="line">missing.sort_values(inplace&#x3D;True) # 排序</span><br><span class="line">missing.plot.bar() # 绘柱状图</span><br><span class="line">plt.tight_layout() # 自动调整子图参数</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/GpS1ts.png" alt="1"></p>
<ul>
<li>通过以上可以很直观的了解哪些列存在 “nan”, 并可以把nan的个数打印，主要的目的在于 nan存在的个数是否真的很大，如果很小一般选择填充，如果使用lgb等树模型可以直接空缺，让树自己去优化，但如果nan存在的过多、可以考虑删掉</li>
</ul>
<h2 id="可视化看下缺省值"><a href="#可视化看下缺省值" class="headerlink" title="可视化看下缺省值"></a>可视化看下缺省值</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## 可视化看下缺省值</span><br><span class="line">msno.matrix(Train_data.sample(250))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/Gp9H0S.png" alt="2"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">msno.bar(Train_data.sample(1000)) # 条形图</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/Gppugx.png" alt="3"></p>
<h2 id="查看异常值检测"><a href="#查看异常值检测" class="headerlink" title="查看异常值检测"></a>查看异常值检测</h2><ul>
<li><p>通过前面info()来熟悉数据类型，可以发现除了notRepairedDamage 为object类型其他都为数字 这里我们把他的几个不同的值都进行显示就知道了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data[&quot;notRepairedDamage&quot;].value_counts()) # 返回包含值和count</span><br></pre></td></tr></table></figure>

<p>  0.0    111361<br>  <code>-</code>       24324<br>  1.0     14315<br>  Name: notRepairedDamage, dtype: int64</p>
</li>
<li><p>可以看出来‘ - ’也为空缺值，因为很多模型对nan有直接的处理，这里我们先不做处理，先替换成nan</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Train_data[&quot;notRepairedDamage&quot;].replace(&quot;-&quot;, np.nan, inplace&#x3D;True) # 将数据中‘-’替换成nan值</span><br><span class="line">print(Train_data[&quot;notRepairedDamage&quot;].value_counts())</span><br></pre></td></tr></table></figure>

<pre><code>0.0    111361
1.0     14315
Name: notRepairedDamage, dtype: int64</code></pre><ul>
<li>再查看nan值情况</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.isnull().sum())</span><br></pre></td></tr></table></figure>

<pre><code>SaleID                   0
name                     0
regDate                  0
model                    1
brand                    0
bodyType              4506
fuelType              8680
gearbox               5981
power                    0
kilometer                0
notRepairedDamage    24324
regionCode               0
seller                   0
offerType                0
creatDate                0
price                    0
v_0                      0
v_1                      0
v_2                      0
v_3                      0
v_4                      0
v_5                      0
v_6                      0
v_7                      0
v_8                      0
v_9                      0
v_10                     0
v_11                     0
v_12                     0
v_13                     0
v_14                     0
dtype: int64</code></pre><ul>
<li>以下两个类别特征严重倾斜，一般不会对预测有什么帮助，故这边先删掉，当然你也可以继续挖掘，但是一般意义不大</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data[&quot;seller&quot;].value_counts())</span><br></pre></td></tr></table></figure>

<pre><code>0    149999
1         1
Name: seller, dtype: int64</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data[&quot;offerType&quot;].value_counts())</span><br></pre></td></tr></table></figure>

<pre><code>0    150000
Name: offerType, dtype: int64</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 删除严重倾斜的数据</span><br><span class="line">del Train_data[&quot;seller&quot;]</span><br><span class="line">del Train_data[&quot;offerType&quot;]</span><br><span class="line">print(Train_data.info())</span><br><span class="line">print(Train_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 29 columns):
 #   Column             Non-Null Count   Dtype  
---  ------             --------------   -----  
 0   SaleID             150000 non-null  int64  
 1   name               150000 non-null  int64  
 2   regDate            150000 non-null  int64  
 3   model              149999 non-null  float64
 4   brand              150000 non-null  int64  
 5   bodyType           145494 non-null  float64
 6   fuelType           141320 non-null  float64
 7   gearbox            144019 non-null  float64
 8   power              150000 non-null  int64  
 9   kilometer          150000 non-null  float64
 10  notRepairedDamage  150000 non-null  object 
 11  regionCode         150000 non-null  int64  
 12  creatDate          150000 non-null  int64  
 13  price              150000 non-null  int64  
 14  v_0                150000 non-null  float64
 15  v_1                150000 non-null  float64
 16  v_2                150000 non-null  float64
 17  v_3                150000 non-null  float64
 18  v_4                150000 non-null  float64
 19  v_5                150000 non-null  float64
 20  v_6                150000 non-null  float64
 21  v_7                150000 non-null  float64
 22  v_8                150000 non-null  float64
 23  v_9                150000 non-null  float64
 24  v_10               150000 non-null  float64
 25  v_11               150000 non-null  float64
 26  v_12               150000 non-null  float64
 27  v_13               150000 non-null  float64
 28  v_14               150000 non-null  float64
dtypes: float64(20), int64(8), object(1)
memory usage: 33.2+ MB
None

(150000, 29)</code></pre><h1 id="了解预测值的分布"><a href="#了解预测值的分布" class="headerlink" title="了解预测值的分布"></a>了解预测值的分布</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data[&quot;price&quot;])</span><br><span class="line">print(Train_data[&quot;price&quot;].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>0         1850
1         3600
2         6222
3         2400
4         5200
      ... 
149995    5900
149996    9500
149997    7500
149998    4999
149999    4700
Name: price, Length: 150000, dtype: int64

500      2337
1500     2158
1200     1922
1000     1850
2500     1821
     ... 
25321       1
8886        1
8801        1
37920       1
8188        1
Name: price, Length: 3763, dtype: int64</code></pre><h2 id="总体分布情况-无界约翰逊分布等）"><a href="#总体分布情况-无界约翰逊分布等）" class="headerlink" title="总体分布情况(无界约翰逊分布等）"></a>总体分布情况(无界约翰逊分布等）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">## 1)总体分布情况(无界约翰逊分布等）</span><br><span class="line">import scipy.stats as st</span><br><span class="line">y &#x3D; Train_data[&quot;price&quot;]</span><br><span class="line">plt.figure(1); plt.title(&quot;Johnson SU&quot;) # 创建新图</span><br><span class="line">sns.distplot(y, kde&#x3D;False, fit&#x3D;st.johnsonsu)</span><br><span class="line">plt.figure(2); plt.title(&quot;Normal&quot;)</span><br><span class="line">sns.distplot(y, kde&#x3D;False, fit&#x3D;st.norm)</span><br><span class="line">plt.figure(3); plt.title(&quot;Log Normal&quot;)</span><br><span class="line">sns.distplot(y, kde&#x3D;False, fit&#x3D;st.lognorm)</span><br><span class="line">plt.show() # 最佳拟合是无界约翰逊分布</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/GpmBL9.png" alt="4"><br><img src="https://s1.ax1x.com/2020/03/26/GpmfQe.png" alt="5"><br><img src="https://s1.ax1x.com/2020/03/26/Gpm4Ld.png" alt="6"></p>
<ul>
<li>价格不服从正态分布，所以在进行回归之前，它必须进行转换。虽然对数变换做得很好，但最佳拟合是无界约翰逊分布</li>
</ul>
<h2 id="查看skewness-and-kurtosis"><a href="#查看skewness-and-kurtosis" class="headerlink" title="查看skewness and kurtosis"></a>查看skewness and kurtosis</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 2)查看skewness and kurtosis</span><br><span class="line">sns.distplot(Train_data[&quot;price&quot;])</span><br><span class="line">print(&quot;Skewness: %f&quot; % Train_data[&quot;price&quot;].skew()) # 偏度</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % Train_data[&quot;price&quot;].kurt()) # 峰度</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Skewness: 3.346487
Kurtosis: 18.995183</code></pre><p><img src="https://s1.ax1x.com/2020/03/26/Gpu55t.png" alt="7"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.skew())</span><br><span class="line">print(Train_data.kurt())</span><br></pre></td></tr></table></figure>

<pre><code>SaleID               6.017846e-17
name                 5.576058e-01
regDate              2.849508e-02
model                1.484388e+00
brand                1.150760e+00
bodyType             9.915299e-01
fuelType             1.595486e+00
gearbox              1.317514e+00
power                6.586318e+01
kilometer           -1.525921e+00
notRepairedDamage    2.430640e+00
regionCode           6.888812e-01
creatDate           -7.901331e+01
price                3.346487e+00
v_0                 -1.316712e+00
v_1                  3.594543e-01
v_2                  4.842556e+00
v_3                  1.062920e-01
v_4                  3.679890e-01
v_5                 -4.737094e+00
v_6                  3.680730e-01
v_7                  5.130233e+00
v_8                  2.046133e-01
v_9                  4.195007e-01
v_10                 2.522046e-02
v_11                 3.029146e+00
v_12                 3.653576e-01
v_13                 2.679152e-01
v_14                -1.186355e+00
dtype: float64

SaleID                 -1.200000
name                   -1.039945
regDate                -0.697308
model                   1.740483
brand                   1.076201
bodyType                0.206937
fuelType                5.880049
gearbox                -0.264161
power                5733.451054
kilometer               1.141934
notRepairedDamage       3.908072
regionCode             -0.340832
creatDate            6881.080328
price                  18.995183
v_0                     3.993841
v_1                    -1.753017
v_2                    23.860591
v_3                    -0.418006
v_4                    -0.197295
v_5                    22.934081
v_6                    -1.742567
v_7                    25.845489
v_8                    -0.636225
v_9                    -0.321491
v_10                   -0.577935
v_11                   12.568731
v_12                    0.268937
v_13                   -0.438274
v_14                    2.393526
dtype: float64</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(Train_data.skew(), color&#x3D;&quot;blue&quot;, axlabel&#x3D;&quot;Skewness&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/GpQ1UA.png" alt="8"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.distplot(Train_data.kurt(), color&#x3D;&quot;orange&quot;, axlabel&#x3D;&quot;Kurtness&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/GpQJ8P.png" alt="9"></p>
<ul>
<li>skew、kurt说明参考<a href="https://www.cnblogs.com/wyy1480/p/10474046.html" target="_blank" rel="noopener">https://www.cnblogs.com/wyy1480/p/10474046.html</a></li>
</ul>
<h2 id="查看预测值的具体频数"><a href="#查看预测值的具体频数" class="headerlink" title="查看预测值的具体频数"></a>查看预测值的具体频数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 3)查看预测值的具体频数</span><br><span class="line">plt.hist(Train_data[&quot;price&quot;], orientation&#x3D;&quot;vertical&quot;, histtype&#x3D;&quot;bar&quot;, color&#x3D;&quot;red&quot;)</span><br><span class="line">plt.show() # 直方图</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/Gp1rcV.png" alt="10"></p>
<ul>
<li>查看频数, 大于20000得值极少，其实这里也可以把这些当作特殊得值（异常值）直接用填充或者删掉，在前面进行</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># log变换之后的分布比较均匀，可以进行log变换进行预测，这也是预测问题常用的trick</span><br><span class="line">plt.hist(np.log(Train_data[&quot;price&quot;]), orientation&#x3D;&quot;vertical&quot;, histtype&#x3D;&quot;bar&quot;, color&#x3D;&quot;red&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/Gp3Z3q.png" alt="11"></p>
<ul>
<li>log变换之后的分布较均匀，可以进行log变换进行预测，这也是预测问题常用的trick</li>
</ul>
<h1 id="特征分为类别特征和数字特征，并对类别特征查看nunique分布"><a href="#特征分为类别特征和数字特征，并对类别特征查看nunique分布" class="headerlink" title="特征分为类别特征和数字特征，并对类别特征查看nunique分布"></a>特征分为类别特征和数字特征，并对类别特征查看nunique分布</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><ul>
<li>name - 汽车编码</li>
<li>regDate - 汽车注册时间</li>
<li>model - 车型编码</li>
<li>brand - 品牌</li>
<li>bodyType - 车身类型</li>
<li>fuelType - 燃油类型</li>
<li>gearbox - 变速箱</li>
<li>power - 汽车功率</li>
<li>kilometer - 汽车行驶公里</li>
<li>notRepairedDamage - 汽车有尚未修复的损坏</li>
<li>regionCode - 看车地区编码</li>
<li>seller - 销售方 【以删】</li>
<li>offerType - 报价类型 【以删】</li>
<li>creatDate - 广告发布时间</li>
<li>price - 汽车价格</li>
<li>v_0’, ‘v_1’, ‘v_2’, ‘v_3’, ‘v_4’, ‘v_5’, ‘v_6’, ‘v_7’, ‘v_8’, ‘v_9’, ‘v_10’, ‘v_11’, ‘v_12’, ‘v_13’,’v_14’【匿名特征，包含v0-14在内15个匿名特征】</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 分离label即预测值</span><br><span class="line">Y_train &#x3D; Train_data[&#39;price&#39;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 这个区别方式适用于没有直接label coding的数据</span><br><span class="line"># 这里不适用，需要人为根据实际含义来区分</span><br><span class="line"># 数字特征</span><br><span class="line"># numeric_features &#x3D; Train_data.select_dtypes(include&#x3D;[np.number])</span><br><span class="line"># numeric_features.columns</span><br><span class="line"># # 类型特征</span><br><span class="line"># categorical_features &#x3D; Train_data.select_dtypes(include&#x3D;[np.object])</span><br><span class="line"># categorical_features.columns</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 数字特征</span><br><span class="line">#numeric_features &#x3D; [&#39;power&#39;, &#39;kilometer&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;, &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;,&#39;v_14&#39; ]</span><br><span class="line"># 类别特征</span><br><span class="line">#categorical_features &#x3D; [&#39;name&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;, &#39;gearbox&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 类别特征nunique分布——Train_data</span><br><span class="line">for cat_fea in categorical_features:</span><br><span class="line">    print(cat_fea+&quot;的特征分布如下：&quot;)</span><br><span class="line">    print(&quot;&#123;&#125;特征有&#123;&#125;个不同的值&quot;.format(cat_fea, Train_data[cat_fea].nunique()))</span><br><span class="line">    print(Train_data[cat_fea].value_counts())</span><br></pre></td></tr></table></figure>


<pre><code>name的特征分布如下：
name特征有99662个不同的值
708       282
387       282
55        280
1541      263
203       233
     ... 
5074        1
7123        1
11221       1
13270       1
174485      1
Name: name, Length: 99662, dtype: int64

model的特征分布如下：
model特征有248个不同的值
0.0      11762
19.0      9573
4.0       8445
1.0       6038
29.0      5186
     ...  
245.0        2
209.0        2
240.0        2
242.0        2
247.0        1
Name: model, Length: 248, dtype: int64

brand的特征分布如下：
brand特征有40个不同的值
0     31480
4     16737
14    16089
10    14249
1     13794
6     10217
9      7306
5      4665
13     3817
11     2945
3      2461
7      2361
16     2223
8      2077
25     2064
27     2053
21     1547
15     1458
19     1388
20     1236
12     1109
22     1085
26      966
30      940
17      913
24      772
28      649
32      592
29      406
37      333
2       321
31      318
18      316
36      228
34      227
33      218
23      186
35      180
38       65
39        9
Name: brand, dtype: int64

bodyType的特征分布如下：
bodyType特征有8个不同的值
0.0    41420
1.0    35272
2.0    30324
3.0    13491
4.0     9609
5.0     7607
6.0     6482
7.0     1289
Name: bodyType, dtype: int64

fuelType的特征分布如下：
fuelType特征有7个不同的值
0.0    91656
1.0    46991
2.0     2212
3.0      262
4.0      118
5.0       45
6.0       36
Name: fuelType, dtype: int64

gearbox的特征分布如下：
gearbox特征有2个不同的值
0.0    111623
1.0     32396
Name: gearbox, dtype: int64

notRepairedDamage的特征分布如下：
notRepairedDamage特征有2个不同的值
0.0    111361
1.0     14315
Name: notRepairedDamage, dtype: int64

regionCode的特征分布如下：
regionCode特征有7905个不同的值
419     369
764     258
125     137
176     136
462     134
       ... 
6414      1
7063      1
4239      1
5931      1
7267      1
Name: regionCode, Length: 7905, dtype: int64</code></pre><h1 id="数字特征分析"><a href="#数字特征分析" class="headerlink" title="数字特征分析"></a>数字特征分析</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numeric_features.append(&quot;price&quot;)</span><br><span class="line">print(numeric_features)</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;power&apos;, 
&apos;kilometer&apos;, 
&apos;v_0&apos;, 
&apos;v_1&apos;, 
&apos;v_2&apos;, 
&apos;v_3&apos;, 
&apos;v_4&apos;, 
&apos;v_5&apos;, 
&apos;v_6&apos;, 
&apos;v_7&apos;, 
&apos;v_8&apos;, 
&apos;v_9&apos;, 
&apos;v_10&apos;, 
&apos;v_11&apos;, 
&apos;v_12&apos;, 
&apos;v_13&apos;, 
&apos;v_14&apos;, 
&apos;price&apos;]</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.head())</span><br></pre></td></tr></table></figure>


<table>
<thead>
<tr>
<th></th>
<th>SaleID</th>
<th>name</th>
<th>regDate</th>
<th>model</th>
<th>…</th>
<th>v_11</th>
<th>v_12</th>
<th>v_13</th>
<th>v_14</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>736</td>
<td>20040402</td>
<td>30.0</td>
<td>…</td>
<td>2.804097</td>
<td>-2.420821</td>
<td>0.795292</td>
<td>0.914762</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2262</td>
<td>20030301</td>
<td>40.0</td>
<td>…</td>
<td>2.096338</td>
<td>-1.030483</td>
<td>-1.722674</td>
<td>0.245522</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>14874</td>
<td>20040403</td>
<td>115.0</td>
<td>…</td>
<td>1.803559</td>
<td>1.565330</td>
<td>-0.832687</td>
<td>-0.229963</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>71865</td>
<td>19960908</td>
<td>109.0</td>
<td>…</td>
<td>1.285940</td>
<td>-0.501868</td>
<td>-2.438353</td>
<td>-0.478699</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>111080</td>
<td>20120103</td>
<td>110.0</td>
<td>…</td>
<td>0.910783</td>
<td>0.931110</td>
<td>2.834518</td>
<td>1.923482</td>
</tr>
</tbody></table>
<p>[5 rows x 29 columns]</p>
<h2 id="相关性分析"><a href="#相关性分析" class="headerlink" title="相关性分析"></a>相关性分析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 1)相关性分析</span><br><span class="line">price_numeric &#x3D; Train_data[numeric_features]</span><br><span class="line">correlation &#x3D; price_numeric.corr() # 返回一个相关系数的矩阵</span><br><span class="line">print(correlation[&quot;price&quot;].sort_values(ascending&#x3D;False),&quot;\n&quot;) # 降序排序</span><br></pre></td></tr></table></figure>



<pre><code>price        1.000000
v_12         0.692823
v_8          0.685798
v_0          0.628397
power        0.219834
v_5          0.164317
v_2          0.085322
v_6          0.068970
v_1          0.060914
v_14         0.035911
v_13        -0.013993
v_7         -0.053024
v_4         -0.147085
v_9         -0.206205
v_10        -0.246175
v_11        -0.275320
kilometer   -0.440519
v_3         -0.730946
Name: price, dtype: float64 </code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f , ax &#x3D; plt.subplots(figsize &#x3D; (7, 7))</span><br><span class="line">plt.title(&quot;Correlation of Numeric Features with Price&quot;)</span><br><span class="line">sns.heatmap(correlation, square&#x3D;True, vmax&#x3D;0.8) # 热图（显示相关系数）</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/GpNCD0.png" alt="12"></p>
<h2 id="查看几个特征的偏度和峰度"><a href="#查看几个特征的偏度和峰度" class="headerlink" title="查看几个特征的偏度和峰度"></a>查看几个特征的偏度和峰度</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 2)查看几个特征的偏度和峰度</span><br><span class="line">for col in numeric_features:</span><br><span class="line">    print(&quot;&#123;:15&#125;&quot;.format(col),&quot;Skewness:&#123;:05.2f&#125;&quot;.format(Train_data[col].skew()),</span><br><span class="line">    &quot;   &quot;,</span><br><span class="line">          &quot;Kurtosis:&#123;:06.2f&#125;&quot;.format(Train_data[col].kurt()))</span><br></pre></td></tr></table></figure>


<pre><code>power           Skewness:65.86     Kurtosis:5733.45
kilometer       Skewness:-1.53     Kurtosis:001.14
v_0             Skewness:-1.32     Kurtosis:003.99
v_1             Skewness:00.36     Kurtosis:-01.75
v_2             Skewness:04.84     Kurtosis:023.86
v_3             Skewness:00.11     Kurtosis:-00.42
v_4             Skewness:00.37     Kurtosis:-00.20
v_5             Skewness:-4.74     Kurtosis:022.93
v_6             Skewness:00.37     Kurtosis:-01.74
v_7             Skewness:05.13     Kurtosis:025.85
v_8             Skewness:00.20     Kurtosis:-00.64
v_9             Skewness:00.42     Kurtosis:-00.32
v_10            Skewness:00.03     Kurtosis:-00.58
v_11            Skewness:03.03     Kurtosis:012.57
v_12            Skewness:00.37     Kurtosis:000.27
v_13            Skewness:00.27     Kurtosis:-00.44
v_14            Skewness:-1.19     Kurtosis:002.39
price           Skewness:03.35     Kurtosis:019.00</code></pre><h2 id="每个数字特征得分布可视化"><a href="#每个数字特征得分布可视化" class="headerlink" title="每个数字特征得分布可视化"></a>每个数字特征得分布可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## 3)每个数字特征得分布可视化</span><br><span class="line">f &#x3D; pd.melt(Train_data, value_vars&#x3D;numeric_features) # 转换</span><br><span class="line">g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2, sharex&#x3D;False,sharey&#x3D;False) # 以”variable“作“格子&quot;绘图</span><br><span class="line"># plt.show()</span><br><span class="line">g &#x3D; g.map(sns.distplot, &quot;value&quot;) # 以”value“绘制到”格子”图中</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/GpNhZV.png" alt="13"></p>
<ul>
<li>可以看出匿名特征相对分布均匀</li>
</ul>
<h2 id="数字特征相互之间的关系可视化"><a href="#数字特征相互之间的关系可视化" class="headerlink" title="数字特征相互之间的关系可视化"></a>数字特征相互之间的关系可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 4）数字特征相互之间的关系可视化</span><br><span class="line">sns.set() # 风格设置</span><br><span class="line">colunms &#x3D; [&quot;price&quot;, &quot;v_12&quot;, &quot;v_8&quot;, &quot;v_0&quot;, &quot;power&quot;, &quot;v_5&quot;, &quot;v_2&quot;, &quot;v_6&quot;, &quot;v_1&quot;, &quot;v_14&quot;]</span><br><span class="line">sns.pairplot(Train_data[colunms],size&#x3D;2, kind&#x3D;&quot;scatter&quot;, diag_kind&#x3D;&quot;kde&quot;) # 多变量图</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/GpaMtO.png" alt="14"></p>
<h2 id="多变量互相回归关系可视化"><a href="#多变量互相回归关系可视化" class="headerlink" title="多变量互相回归关系可视化"></a>多变量互相回归关系可视化</h2><ul>
<li><p>此处是多变量之间的关系可视化，可视化更多学习可参考很不错的文章<a href="https://www.jianshu.com/p/6e18d21a4cad" target="_blank" rel="noopener">https://www.jianshu.com/p/6e18d21a4cad</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.columns)</span><br></pre></td></tr></table></figure>

<p>  Index([‘SaleID’, ‘name’, ‘regDate’, ‘model’, ‘brand’, ‘bodyType’, ‘fuelType’,</p>
<pre><code> &apos;gearbox&apos;, &apos;power&apos;, &apos;kilometer&apos;, &apos;notRepairedDamage&apos;, &apos;regionCode&apos;,
 &apos;creatDate&apos;, &apos;price&apos;, &apos;v_0&apos;, &apos;v_1&apos;, &apos;v_2&apos;, &apos;v_3&apos;, &apos;v_4&apos;, &apos;v_5&apos;, &apos;v_6&apos;,
 &apos;v_7&apos;, &apos;v_8&apos;, &apos;v_9&apos;, &apos;v_10&apos;, &apos;v_11&apos;, &apos;v_12&apos;, &apos;v_13&apos;, &apos;v_14&apos;],
dtype=&apos;object&apos;)</code></pre></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Y_train)</span><br></pre></td></tr></table></figure>
<pre><code>0         1850
1         3600
2         6222
3         2400
4         5200
      ... 
149995    5900
149996    9500
149997    7500
149998    4999
149999    4700
Name: price, Length: 150000, dtype: int64</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">## 5)多变量互相关系回归关系可视化</span><br><span class="line">fig,((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) &#x3D; plt.subplots(nrows&#x3D;5, ncols&#x3D;2, figsize&#x3D;(24, 20)) # 生成5行2列十个子图</span><br><span class="line"># [&#39;v_12&#39;, &#39;v_8&#39; , &#39;v_0&#39;, &#39;power&#39;, &#39;v_5&#39;,  &#39;v_2&#39;, &#39;v_6&#39;, &#39;v_1&#39;, &#39;v_14&#39;]</span><br><span class="line">v_12_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&quot;v_12&quot;]], axis&#x3D;1) # 合并成一列</span><br><span class="line">#print(v_12_scatter_plot)</span><br><span class="line">sns.regplot(x&#x3D;&quot;v_12&quot;, y&#x3D;&quot;price&quot;, data&#x3D;v_12_scatter_plot,scatter&#x3D;True,fit_reg&#x3D;True,ax&#x3D;ax1) # 数据与回归模型拟合</span><br><span class="line"></span><br><span class="line">v_8_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_8&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_8&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_8_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax2)</span><br><span class="line"></span><br><span class="line">v_0_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_0&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_0&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_0_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax3)</span><br><span class="line"></span><br><span class="line">power_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;power&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;power&#39;,y &#x3D; &#39;price&#39;,data &#x3D; power_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax4)</span><br><span class="line"></span><br><span class="line">v_5_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_5&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_5&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_5_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax5)</span><br><span class="line"></span><br><span class="line">v_2_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_2&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_2&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_2_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax6)</span><br><span class="line"></span><br><span class="line">v_6_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_6&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_6&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_6_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax7)</span><br><span class="line"></span><br><span class="line">v_1_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_1&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_1&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_1_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax8)</span><br><span class="line"></span><br><span class="line">v_14_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_14&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_14&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_14_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax9)</span><br><span class="line"></span><br><span class="line">v_13_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_13&#39;]],axis &#x3D; 1)</span><br><span class="line">sns.regplot(x&#x3D;&#39;v_13&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_13_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax10)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/Gp04C8.png" alt="15"></p>
<h1 id="类别特征分析"><a href="#类别特征分析" class="headerlink" title="类别特征分析"></a>类别特征分析</h1><h2 id="nunique分布"><a href="#nunique分布" class="headerlink" title="nunique分布"></a>nunique分布</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## 1）nunique分布</span><br><span class="line">for fea in categorical_features:</span><br><span class="line">    print(Train_data[fea].nunique())</span><br></pre></td></tr></table></figure>
<pre><code>99662
248
40
8
7
2
2
7905</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(categorical_features)</span><br></pre></td></tr></table></figure>

<pre><code>[&apos;name&apos;, 
&apos;model&apos;, 
&apos;brand&apos;, 
&apos;bodyType&apos;, 
&apos;fuelType&apos;, 
&apos;gearbox&apos;, 
&apos;notRepairedDamage&apos;, 
&apos;regionCode&apos;]</code></pre><h2 id="类别特征箱形图可视化"><a href="#类别特征箱形图可视化" class="headerlink" title="类别特征箱形图可视化"></a>类别特征箱形图可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">## 2)类别箱形图可视化</span><br><span class="line"># 因为 name和 regionCode的类别太稀疏了，这里我们把不稀疏的几类画一下</span><br><span class="line">categorical_features &#x3D; [&quot;model&quot;,</span><br><span class="line">                        &quot;brand&quot;,</span><br><span class="line">                        &quot;bodyType&quot;,</span><br><span class="line">                        &quot;fuelType&quot;,</span><br><span class="line">                        &quot;gearbox&quot;,</span><br><span class="line">                        &quot;notRepairedDamage&quot;]</span><br><span class="line">for c in categorical_features:</span><br><span class="line">    Train_data[c] &#x3D; Train_data[c].astype(&quot;category&quot;) # 强制转换数据类型</span><br><span class="line">    if Train_data[c].isnull().any(): # 检查字段缺失</span><br><span class="line">        Train_data[c] &#x3D; Train_data[c].cat.add_categories([&quot;MISSING&quot;]) # 添加新类别</span><br><span class="line">        Train_data[c] &#x3D; Train_data[c].fillna(&quot;MISSING&quot;) # 填充为NAN的值</span><br><span class="line">def boxplot(x, y, **kwargs):</span><br><span class="line">    sns.boxplot(x&#x3D;x, y&#x3D;y) # 箱形图</span><br><span class="line">    x&#x3D;plt.xticks(rotation&#x3D;90) #  设置坐标轴</span><br><span class="line"></span><br><span class="line">f &#x3D; pd.melt(Train_data, id_vars&#x3D;[&quot;price&quot;], value_vars&#x3D;categorical_features)</span><br><span class="line">g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2, sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line">g &#x3D; g.map(boxplot, &quot;value&quot;, &quot;price&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/GpDs0A.png" alt="16"></p>
<h2 id="类别特征的小提琴图可视化"><a href="#类别特征的小提琴图可视化" class="headerlink" title="类别特征的小提琴图可视化"></a>类别特征的小提琴图可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(Train_data.columns)</span><br></pre></td></tr></table></figure>

<pre><code>Index([&apos;SaleID&apos;, &apos;name&apos;, &apos;regDate&apos;, &apos;model&apos;, &apos;brand&apos;, &apos;bodyType&apos;, &apos;fuelType&apos;,
       &apos;gearbox&apos;, &apos;power&apos;, &apos;kilometer&apos;, &apos;notRepairedDamage&apos;, &apos;regionCode&apos;,
       &apos;creatDate&apos;, &apos;price&apos;, &apos;v_0&apos;, &apos;v_1&apos;, &apos;v_2&apos;, &apos;v_3&apos;, &apos;v_4&apos;, &apos;v_5&apos;, &apos;v_6&apos;,
       &apos;v_7&apos;, &apos;v_8&apos;, &apos;v_9&apos;, &apos;v_10&apos;, &apos;v_11&apos;, &apos;v_12&apos;, &apos;v_13&apos;, &apos;v_14&apos;],
      dtype=&apos;object&apos;)</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## 3)类别特征的小提琴图可视化</span><br><span class="line">catg_list &#x3D; categorical_features</span><br><span class="line">target &#x3D; &quot;price&quot;</span><br><span class="line">for catg in catg_list:</span><br><span class="line">    sns.violinplot(x&#x3D;catg,y&#x3D;target,data&#x3D;Train_data)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/GprvPP.png" alt="17"><br><img src="https://s1.ax1x.com/2020/03/26/GpsmxU.png" alt="18"><br><img src="https://s1.ax1x.com/2020/03/26/Gps1aR.png" alt="19"><br><img src="https://s1.ax1x.com/2020/03/26/GpymFI.png" alt="20"><br><img src="https://s1.ax1x.com/2020/03/26/GpynYt.png" alt="21"><br><img src="https://s1.ax1x.com/2020/03/26/GpyQl8.png" alt="22"></p>
<h2 id="类别特征的柱形图可视化"><a href="#类别特征的柱形图可视化" class="headerlink" title="类别特征的柱形图可视化"></a>类别特征的柱形图可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(categorical_features)</span><br></pre></td></tr></table></figure>

<pre><code>[&apos;model&apos;, 
&apos;brand&apos;, 
&apos;bodyType&apos;, 
&apos;fuelType&apos;, 
&apos;gearbox&apos;, 
&apos;notRepairedDamage&apos;]</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## 4)类别特征的柱形图可视化</span><br><span class="line">def bar_plot(x,y,**kwargs): # 柱形图</span><br><span class="line">    sns.barplot(x&#x3D;x,y&#x3D;y)</span><br><span class="line">    x&#x3D;plt.xticks(rotation&#x3D;90)</span><br><span class="line">f &#x3D; pd.melt(Train_data, id_vars&#x3D;[&quot;price&quot;], value_vars&#x3D;categorical_features)</span><br><span class="line">g &#x3D; sns.FacetGrid(f, col&#x3D;&quot;variable&quot;,col_wrap&#x3D;2,sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line">g &#x3D; g.map(bar_plot, &quot;value&quot;, &quot;price&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://s1.ax1x.com/2020/03/26/Gp6mB4.png" alt="23"></p>
<h2 id="类别特征的每个类别频数可视化"><a href="#类别特征的每个类别频数可视化" class="headerlink" title="类别特征的每个类别频数可视化"></a>类别特征的每个类别频数可视化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## 5)类别特征的每个类别频数可视化</span><br><span class="line">def count_plot(x,**kwargs): # 计数直方图</span><br><span class="line">    sns.countplot(x&#x3D;x)</span><br><span class="line">    x&#x3D;plt.xticks(rotation&#x3D;90)</span><br><span class="line">f &#x3D; pd.melt(Train_data,value_vars&#x3D;categorical_features)</span><br><span class="line">g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2,sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line">g &#x3D; g.map(count_plot,&quot;value&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/03/26/Gp6x8x.png" alt="24"></p>
<h2 id="用pandas-profiling生成数据报告"><a href="#用pandas-profiling生成数据报告" class="headerlink" title="用pandas_profiling生成数据报告"></a>用pandas_profiling生成数据报告</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 生成数据报告</span><br><span class="line">import pandas_profiling</span><br><span class="line"></span><br><span class="line">pfr &#x3D; pandas_profiling.ProfileReport(Train_data)</span><br><span class="line">pfr.to_file(&quot;.&#x2F;example.html&quot;)</span><br></pre></td></tr></table></figure>

<h1 id="代码片段"><a href="#代码片段" class="headerlink" title="代码片段"></a>代码片段</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br></pre></td><td class="code"><pre><span class="line"># 导入warnings包，利用过滤器来实现忽略警告语句</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">import missingno as msno</span><br><span class="line"></span><br><span class="line">## pd.set_option(&#39;display.max_columns&#39;, None)# 显示所有列</span><br><span class="line">## pd.set_option(&#39;display.max_row&#39;, None)# 显示所有行</span><br><span class="line">## 1)载入训练集和测试集</span><br><span class="line">Train_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_train_20200313.csv&quot;, sep &#x3D; &quot; &quot;)</span><br><span class="line">Test_data &#x3D; pd.read_csv(&quot;.&#x2F;datalab&#x2F;used_car_testA_20200313.csv&quot;, sep &#x3D; &quot; &quot;)</span><br><span class="line"></span><br><span class="line">## 2)简略观察数据（head()+shape)</span><br><span class="line">#print(Train_data.head().append(Train_data.tail()))</span><br><span class="line">#print(Train_data.shape)</span><br><span class="line">#</span><br><span class="line"># ## 3)通过describe()来熟悉相关统计量</span><br><span class="line"># print(Train_data.describe())</span><br><span class="line">#</span><br><span class="line"># ## 4)通过info()来熟悉数据类型</span><br><span class="line"># print(Train_data.info())</span><br><span class="line">#</span><br><span class="line"># ## 5)判断数据缺失和异常</span><br><span class="line"># print(Train_data.isnull().sum())</span><br><span class="line">#</span><br><span class="line">#nan可视化</span><br><span class="line"># missing &#x3D; Train_data.isnull().sum()</span><br><span class="line"># missing &#x3D; missing[missing &gt; 0]</span><br><span class="line"># missing.sort_values(inplace&#x3D;True) # 排序</span><br><span class="line"># missing.plot.bar() # 绘柱状图</span><br><span class="line"># plt.tight_layout() # 自动调整子图参数</span><br><span class="line"># plt.show()</span><br><span class="line"># # # 可视化看下缺省值</span><br><span class="line"># msno.matrix(Train_data.sample(250))</span><br><span class="line"># # plt.show()</span><br><span class="line"># msno.bar(Train_data.sample(1000)) # 条形图</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 6)查看异常值检测</span><br><span class="line"># Train_data.info()</span><br><span class="line">## print(Train_data[&quot;notRepairedDamage&quot;].value_counts()) # 返回包含值和count</span><br><span class="line">Train_data[&quot;notRepairedDamage&quot;].replace(&quot;-&quot;, np.nan, inplace&#x3D;True) # 将数据中‘-’替换成nan值</span><br><span class="line"># print(Train_data.isnull().sum())</span><br><span class="line"></span><br><span class="line">#print(Train_data[&quot;notRepairedDamage&quot;].value_counts())</span><br><span class="line">#Test_data.info()</span><br><span class="line">##print(Test_data[&quot;notRepairedDamage&quot;].value_counts())</span><br><span class="line">#Test_data[&quot;notRepairedDamage&quot;].replace(&quot;-&quot;, np.nan, inplace&#x3D;True)</span><br><span class="line">##print(Test_data[&quot;notRepairedDamage&quot;].value_counts())</span><br><span class="line"></span><br><span class="line"># 删除严重倾斜的数据</span><br><span class="line">#print(Train_data[&quot;seller&quot;].value_counts())</span><br><span class="line">#print(Train_data[&quot;offerType&quot;].value_counts())</span><br><span class="line"># print(Test_data[&quot;seller&quot;].value_counts())</span><br><span class="line"># print(Test_data[&quot;offerType&quot;].value_counts())</span><br><span class="line"></span><br><span class="line">del Train_data[&quot;seller&quot;]</span><br><span class="line">del Train_data[&quot;offerType&quot;]</span><br><span class="line"># print(Train_data.info())</span><br><span class="line"># print(Train_data.shape)</span><br><span class="line">#del Test_data[&quot;seller&quot;]</span><br><span class="line">#del Test_data[&quot;offerType&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 了解预测值的分布</span><br><span class="line"># print(Train_data[&quot;price&quot;])</span><br><span class="line"># print(Train_data[&quot;price&quot;].value_counts())</span><br><span class="line"></span><br><span class="line">## 1)总体分布情况(无界约翰逊分布等）</span><br><span class="line">import scipy.stats as st</span><br><span class="line"># y &#x3D; Train_data[&quot;price&quot;]</span><br><span class="line"># plt.figure(1); plt.title(&quot;Johnson SU&quot;) # 创建新图</span><br><span class="line"># sns.distplot(y, kde&#x3D;False, fit&#x3D;st.johnsonsu)</span><br><span class="line"># plt.figure(2); plt.title(&quot;Normal&quot;)</span><br><span class="line"># sns.distplot(y, kde&#x3D;False, fit&#x3D;st.norm)</span><br><span class="line"># plt.figure(3); plt.title(&quot;Log Normal&quot;)</span><br><span class="line"># sns.distplot(y, kde&#x3D;False, fit&#x3D;st.lognorm)</span><br><span class="line"># plt.show() # 最佳拟合是无界约翰逊分布</span><br><span class="line"></span><br><span class="line">## 2)查看skewness and kurtosis</span><br><span class="line"># sns.distplot(Train_data[&quot;price&quot;])</span><br><span class="line"># print(&quot;Skewness: %f&quot; % Train_data[&quot;price&quot;].skew()) # 偏度</span><br><span class="line"># print(&quot;Kurtosis: %f&quot; % Train_data[&quot;price&quot;].kurt()) # 峰度</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line"># print(Train_data.skew())</span><br><span class="line"># print(Train_data.kurt())</span><br><span class="line"># sns.distplot(Train_data.skew(), color&#x3D;&quot;blue&quot;, axlabel&#x3D;&quot;Skewness&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"># sns.distplot(Train_data.kurt(), color&#x3D;&quot;orange&quot;, axlabel&#x3D;&quot;Kurtness&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line"># 3)查看预测值的具体频数</span><br><span class="line"># plt.hist(Train_data[&quot;price&quot;], orientation&#x3D;&quot;vertical&quot;, histtype&#x3D;&quot;bar&quot;, color&#x3D;&quot;red&quot;)</span><br><span class="line"># plt.show() # 直方图</span><br><span class="line"># log变换之后的分布比较均匀，可以进行log变换进行预测，这也是预测问题常用的trick</span><br><span class="line"># plt.hist(np.log(Train_data[&quot;price&quot;]), orientation&#x3D;&quot;vertical&quot;, histtype&#x3D;&quot;bar&quot;, color&#x3D;&quot;red&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 查看特征</span><br><span class="line"># 分离label即预测值</span><br><span class="line">Y_train &#x3D; Train_data[&quot;price&quot;]</span><br><span class="line">## 这个区别方式适用于没有直接label coding的数据</span><br><span class="line">## 这里不适用，需要人为根据实际含义来区分</span><br><span class="line">## 数字特征</span><br><span class="line">## numeric_features &#x3D; Train_data.select_dtypes(include&#x3D;[np.number])</span><br><span class="line">## numeric_features.columns</span><br><span class="line">## # 类型特征</span><br><span class="line">## categorical_features &#x3D; Train_data.select_dtypes(include&#x3D;[np.object])</span><br><span class="line">## categorical_features.columns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数字特征</span><br><span class="line">numeric_features &#x3D; [&#39;power&#39;, &#39;kilometer&#39;, &#39;v_0&#39;, &#39;v_1&#39;, &#39;v_2&#39;, &#39;v_3&#39;, &#39;v_4&#39;, &#39;v_5&#39;, &#39;v_6&#39;, &#39;v_7&#39;, &#39;v_8&#39;, &#39;v_9&#39;, &#39;v_10&#39;, &#39;v_11&#39;, &#39;v_12&#39;, &#39;v_13&#39;,&#39;v_14&#39; ]</span><br><span class="line"># 类别特征</span><br><span class="line">categorical_features &#x3D; [&#39;name&#39;, &#39;model&#39;, &#39;brand&#39;, &#39;bodyType&#39;, &#39;fuelType&#39;, &#39;gearbox&#39;, &#39;notRepairedDamage&#39;, &#39;regionCode&#39;]</span><br><span class="line">## 类别特征nunique分布——Train_data</span><br><span class="line"># for cat_fea in categorical_features:</span><br><span class="line">#     print(cat_fea+&quot;的特征分布如下：&quot;)</span><br><span class="line">#     print(&quot;&#123;&#125;特征有&#123;&#125;个不同的值&quot;.format(cat_fea, Train_data[cat_fea].nunique()))</span><br><span class="line">#     print(Train_data[cat_fea].value_counts())</span><br><span class="line">## 类别特征nunique分布——Test_data</span><br><span class="line"># for cat_fea in categorical_features:</span><br><span class="line">#     print(cat_fea+&quot;的特征分布如下：&quot;)</span><br><span class="line">#     print(&quot;&#123;&#125;特征有&#123;&#125;个不同的值&quot;.format(cat_fea, Test_data[cat_fea].nunique()))</span><br><span class="line">#     print(Test_data[cat_fea].value_counts())</span><br><span class="line"></span><br><span class="line">## 数字特征分析</span><br><span class="line">numeric_features.append(&quot;price&quot;)</span><br><span class="line"># print(numeric_features)</span><br><span class="line">#print(Train_data.head())</span><br><span class="line">## 1)相关性分析</span><br><span class="line">price_numeric &#x3D; Train_data[numeric_features]</span><br><span class="line">correlation &#x3D; price_numeric.corr() # 返回一个相关系数的矩阵</span><br><span class="line"># print(correlation[&quot;price&quot;].sort_values(ascending&#x3D;False),&quot;\n&quot;) # 降序排序</span><br><span class="line"></span><br><span class="line"># f , ax &#x3D; plt.subplots(figsize &#x3D; (7, 7))</span><br><span class="line"># plt.title(&quot;Correlation of Numeric Features with Price&quot;)</span><br><span class="line"># sns.heatmap(correlation, square&#x3D;True, vmax&#x3D;0.8) # 热图（显示相关系数）</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 2)查看几个特征的偏度和峰度</span><br><span class="line"># for col in numeric_features:</span><br><span class="line">#     print(&quot;&#123;:15&#125;&quot;.format(col),&quot;Skewness:&#123;:05.2f&#125;&quot;.format(Train_data[col].skew()),</span><br><span class="line">#     &quot;   &quot;,</span><br><span class="line">#           &quot;Kurtosis:&#123;:06.2f&#125;&quot;.format(Train_data[col].kurt()))</span><br><span class="line"></span><br><span class="line">## 3)每个数字特征得分布可视化</span><br><span class="line"># f &#x3D; pd.melt(Train_data, value_vars&#x3D;numeric_features) # 转换</span><br><span class="line"># g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2, sharex&#x3D;False,sharey&#x3D;False) # 以”variable“作“格子&quot;绘图</span><br><span class="line"># # plt.show()</span><br><span class="line"># g &#x3D; g.map(sns.distplot, &quot;value&quot;) # 以”value“绘制到”格子”图中</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 4）数字特征相互之间的关系可视化</span><br><span class="line"># sns.set() # 风格设置</span><br><span class="line"># colunms &#x3D; [&quot;price&quot;, &quot;v_12&quot;, &quot;v_8&quot;, &quot;v_0&quot;, &quot;power&quot;, &quot;v_5&quot;, &quot;v_2&quot;, &quot;v_6&quot;, &quot;v_1&quot;, &quot;v_14&quot;]</span><br><span class="line"># sns.pairplot(Train_data[colunms],size&#x3D;2, kind&#x3D;&quot;scatter&quot;, diag_kind&#x3D;&quot;kde&quot;) # 多变量图</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line"># print(Train_data.columns)</span><br><span class="line"># print(Y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 5)多变量互相关系回归关系可视化</span><br><span class="line"># fig,((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) &#x3D; plt.subplots(nrows&#x3D;5, ncols&#x3D;2, figsize&#x3D;(24, 20)) # 生成5行2列十个子图</span><br><span class="line"># # [&#39;v_12&#39;, &#39;v_8&#39; , &#39;v_0&#39;, &#39;power&#39;, &#39;v_5&#39;,  &#39;v_2&#39;, &#39;v_6&#39;, &#39;v_1&#39;, &#39;v_14&#39;]</span><br><span class="line"># v_12_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&quot;v_12&quot;]], axis&#x3D;1) # 合并成一列</span><br><span class="line"># #print(v_12_scatter_plot)</span><br><span class="line"># sns.regplot(x&#x3D;&quot;v_12&quot;, y&#x3D;&quot;price&quot;, data&#x3D;v_12_scatter_plot,scatter&#x3D;True,fit_reg&#x3D;True,ax&#x3D;ax1) # 数据与回归模型拟合</span><br><span class="line">#</span><br><span class="line"># v_8_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_8&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_8&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_8_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax2)</span><br><span class="line">#</span><br><span class="line"># v_0_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_0&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_0&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_0_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax3)</span><br><span class="line">#</span><br><span class="line"># power_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;power&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;power&#39;,y &#x3D; &#39;price&#39;,data &#x3D; power_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax4)</span><br><span class="line">#</span><br><span class="line"># v_5_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_5&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_5&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_5_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax5)</span><br><span class="line">#</span><br><span class="line"># v_2_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_2&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_2&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_2_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax6)</span><br><span class="line">#</span><br><span class="line"># v_6_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_6&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_6&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_6_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax7)</span><br><span class="line">#</span><br><span class="line"># v_1_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_1&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_1&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_1_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax8)</span><br><span class="line">#</span><br><span class="line"># v_14_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_14&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_14&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_14_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax9)</span><br><span class="line">#</span><br><span class="line"># v_13_scatter_plot &#x3D; pd.concat([Y_train,Train_data[&#39;v_13&#39;]],axis &#x3D; 1)</span><br><span class="line"># sns.regplot(x&#x3D;&#39;v_13&#39;,y &#x3D; &#39;price&#39;,data &#x3D; v_13_scatter_plot,scatter&#x3D; True, fit_reg&#x3D;True, ax&#x3D;ax10)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line"># 类别特征分析</span><br><span class="line">## 1）nunique分布</span><br><span class="line"># for fea in categorical_features:</span><br><span class="line">#     print(Train_data[fea].nunique())</span><br><span class="line">#</span><br><span class="line"># print(categorical_features)</span><br><span class="line"></span><br><span class="line">## 2)类别箱形图可视化</span><br><span class="line"># 因为 name和 regionCode的类别太稀疏了，这里我们把不稀疏的几类画一下</span><br><span class="line">categorical_features &#x3D; [&quot;model&quot;,</span><br><span class="line">                        &quot;brand&quot;,</span><br><span class="line">                        &quot;bodyType&quot;,</span><br><span class="line">                        &quot;fuelType&quot;,</span><br><span class="line">                        &quot;gearbox&quot;,</span><br><span class="line">                        &quot;notRepairedDamage&quot;]</span><br><span class="line">for c in categorical_features:</span><br><span class="line">    Train_data[c] &#x3D; Train_data[c].astype(&quot;category&quot;) # 强制转换数据类型</span><br><span class="line">    if Train_data[c].isnull().any(): # 检查字段缺失</span><br><span class="line">        Train_data[c] &#x3D; Train_data[c].cat.add_categories([&quot;MISSING&quot;]) # 添加新类别</span><br><span class="line">        Train_data[c] &#x3D; Train_data[c].fillna(&quot;MISSING&quot;) # 填充为NAN的值</span><br><span class="line"># def boxplot(x, y, **kwargs):</span><br><span class="line">#     sns.boxplot(x&#x3D;x, y&#x3D;y) # 箱形图</span><br><span class="line">#     x&#x3D;plt.xticks(rotation&#x3D;90) #  设置坐标轴</span><br><span class="line">#</span><br><span class="line"># f &#x3D; pd.melt(Train_data, id_vars&#x3D;[&quot;price&quot;], value_vars&#x3D;categorical_features)</span><br><span class="line"># g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2, sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line"># g &#x3D; g.map(boxplot, &quot;value&quot;, &quot;price&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 3)类别特征的小提琴图可视化</span><br><span class="line">#print(Train_data.columns)</span><br><span class="line"># catg_list &#x3D; categorical_features</span><br><span class="line"># target &#x3D; &quot;price&quot;</span><br><span class="line"># for catg in catg_list:</span><br><span class="line">#     sns.violinplot(x&#x3D;catg,y&#x3D;target,data&#x3D;Train_data)</span><br><span class="line">#     plt.show()</span><br><span class="line"></span><br><span class="line"># print(categorical_features)</span><br><span class="line"></span><br><span class="line">## 4)类别特征的柱形图可视化</span><br><span class="line"># def bar_plot(x,y,**kwargs): # 柱形图</span><br><span class="line">#     sns.barplot(x&#x3D;x,y&#x3D;y)</span><br><span class="line">#     x&#x3D;plt.xticks(rotation&#x3D;90)</span><br><span class="line"># f &#x3D; pd.melt(Train_data, id_vars&#x3D;[&quot;price&quot;], value_vars&#x3D;categorical_features)</span><br><span class="line"># g &#x3D; sns.FacetGrid(f, col&#x3D;&quot;variable&quot;,col_wrap&#x3D;2,sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line"># g &#x3D; g.map(bar_plot, &quot;value&quot;, &quot;price&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 5)类别特征的每个类别频数可视化</span><br><span class="line"># def count_plot(x,**kwargs): # 计数直方图</span><br><span class="line">#     sns.countplot(x&#x3D;x)</span><br><span class="line">#     x&#x3D;plt.xticks(rotation&#x3D;90)</span><br><span class="line"># f &#x3D; pd.melt(Train_data,value_vars&#x3D;categorical_features)</span><br><span class="line"># g &#x3D; sns.FacetGrid(f,col&#x3D;&quot;variable&quot;, col_wrap&#x3D;2,sharex&#x3D;False,sharey&#x3D;False,size&#x3D;5)</span><br><span class="line"># g &#x3D; g.map(count_plot,&quot;value&quot;)</span><br><span class="line"># plt.show()</span><br><span class="line"></span><br><span class="line">## 生成数据报告</span><br><span class="line">import pandas_profiling</span><br><span class="line">#</span><br><span class="line"># pfr &#x3D; pandas_profiling.ProfileReport(Train_data)</span><br><span class="line"># pfr.to_file(&quot;.&#x2F;example.html&quot;)</span><br></pre></td></tr></table></figure>

<h1 id="经验总结"><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h1><p>所给出的EDA步骤为广为普遍的步骤，在实际的不管是工程还是比赛过程中，这只是最开始的一步，也是最基本的一步。</p>
<p>接下来一般要结合模型的效果以及特征工程等来分析数据的实际建模情况，根据自己的一些理解，查阅文献，对实际问题做出判断和深入的理解。</p>
<h2 id="最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征"><a href="#最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征" class="headerlink" title="最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征"></a>最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征</h2><p>数据探索在机器学习中我们一般称为EDA（Exploratory Data Analysis）：</p>
<blockquote>
<p>是指对已有的数据（特别是调查或观察得来的原始数据）在尽量少的先验假定下进行探索，通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方&gt;法。</p>
</blockquote>
<p>数据探索有利于我们发现数据的一些特性，数据之间的关联性，对于后续的特征构建是很有帮助的。</p>
<ol>
<li><p>对于数据的初步分析（直接查看数据，或.sum(), .mean()，.descirbe()等统计函数）可以从：样本数量，训练集数量，是否有时间特征，是否是时许问题，特征所表示的含义（非匿名特征），特征类型（字符类似，int，float，time），特征的缺失情况（注意缺失的在数据中的表现形式，有些是空的有些是”NAN”符号等），特征的均值方差情况。</p>
</li>
<li><p>分析记录某些特征值缺失占比30%以上样本的缺失处理，有助于后续的模型验证和调节，分析特征应该是填充（填充方式是什么，均值填充，0填充，众数填充等），还是舍去，还是先做样本分类用不同的特征模型去预测。</p>
</li>
<li><p>对于异常值做专门的分析，分析特征异常的label是否为异常值（或者偏离均值较远或者是特殊符号）,异常值是否应该剔除，还是用正常值填充，是记录异常，还是机器本身异常等。</p>
</li>
<li><p>对于Label做专门的分析，分析标签的分布情况等。</p>
</li>
<li><p>进步分析可以通过对特征作图，特征和label联合做图（统计图，离散图），直观了解特征的分布情况，通过这一步也可以发现数据之中的一些异常值等，通过箱型图分析一些特征值的偏离情况，对于特征和特征联合作图，对于特征和label联合作图，分析其中的一些关联性。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://happybear1234.github.io/2020/03/21/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="happybear">
      <meta itemprop="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="happybear">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/21/Datawhale%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Task1/" class="post-title-link" itemprop="url">Datawhale零基础入门数据挖掘-Task1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-21 18:25:46" itemprop="dateCreated datePublished" datetime="2020-03-21T18:25:46+08:00">2020-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-23 16:21:01" itemprop="dateModified" datetime="2020-03-23T16:21:01+08:00">2020-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8F%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">数据挖掘及机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-users"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="firestore-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>学习背景:由Datawhale与天池开放的零基础入门数据挖掘赛事-<a href="https://tianchi.aliyun.com/competition/entrance/231784/introduction?spm=5176.12281949.1003.2.493e2448KgHsEd" target="_blank" rel="noopener">二手车交易价格预测</a></p>
</li>
<li><p>赛题概括:赛题以预测二手车的交易价格为任务，数据集报名后可见并可下载，该数据来自某交易平台的二手车交易记录，总数据量超过40w，包含31列变量信息，其中15列为匿名变量。为了保证比赛的公平性，将会从中抽取15万条作为训练集，5万条作为测试集A，5万条作为测试集B，同时会对name、model、brand和regionCode等信息进行脱敏。</p>
</li>
</ul>
<h1 id="赛题分析"><a href="#赛题分析" class="headerlink" title="赛题分析"></a>赛题分析</h1><h2 id="数据概括"><a href="#数据概括" class="headerlink" title="数据概括"></a>数据概括</h2><p>一般而言，对于数据在比赛界面都有对应的数据概况介绍（匿名特征除外），说明列的性质特征。了解列的性质会有助于我们对于数据的理解和后续分析。 Tip:匿名特征，就是未告知数据列所属的性质的特征列。</p>
<blockquote>
<p>train.csv</p>
<ul>
<li>SaleID - 销售样本ID</li>
<li>name - 汽车编码</li>
<li>regDate - 汽车注册时间</li>
<li>model - 车型编码</li>
<li>brand - 品牌</li>
<li>bodyType - 车身类型</li>
<li>fuelType - 燃油类型</li>
<li>gearbox - 变速箱</li>
<li>power - 汽车功率</li>
<li>kilometer - 汽车行驶公里</li>
<li>notRepairedDamage - 汽车有尚未修复的损坏</li>
<li>regionCode - 看车地区编码</li>
<li>seller - 销售方</li>
<li>offerType - 报价类型</li>
<li>creatDate - 广告发布时间</li>
<li>price - 汽车价格</li>
<li>‘v_0’, ‘v_1’, ‘v_2’, ‘v_3’, ‘v_4’, ‘v_5’, ‘v_6’, ‘v_7’, ‘v_8’, ‘v_9’, ‘v_10’, ‘v_11’, ‘v_12’, ‘v_13’,’v_14’ 【匿名特征，包含v0-14在内15个匿名特征】 　</li>
</ul>
</blockquote>
<h2 id="评测标准"><a href="#评测标准" class="headerlink" title="评测标准"></a>评测标准</h2><p>赛题评价目标为MAE(Mean Absolute Error):</p>
<blockquote>
<p><img src="https://s1.ax1x.com/2020/03/21/8hVCfs.png" alt=""><br>MAE越小，说明模型预测得越准确</p>
</blockquote>
<h2 id="预测建模"><a href="#预测建模" class="headerlink" title="预测建模"></a>预测建模</h2><ul>
<li>预测建模就是使用历史数据建立一个模型，去给没有答案的新数据做预测的问题</li>
</ul>
<p>关于预测建模，可以在下面这篇文章中了解更多信息:</p>
<blockquote>
<p>Gentle Introduction to Predictive Modeling: <a href="https://machinelearningmastery.com/gentle-introduction-to-predictive-modeling/" target="_blank" rel="noopener">https://machinelearningmastery.com/gentle-introduction-to-predictive-modeling/</a></p>
</blockquote>
<p>预测建模可以被描述成一个近似求取从输入变量（X）到输出变量（y）的映射函数的数学问题。这被称为函数逼近问题</p>
<p>建模算法的任务就是在给定的可用时间和资源的限制下，去寻找最佳映射函数。更多关于机器学习中应用逼近函数的内容，请参阅下面这篇文章：</p>
<blockquote>
<p>机器学习是如何运行的（how machine learning work,<a href="https://machinelearningmastery.com/how-machine-learning-algorithms-work/" target="_blank" rel="noopener">https://machinelearningmastery.com/how-machine-learning-algorithms-work/</a>)</p>
</blockquote>
<p>一般而言，我们可以将函数逼近任务划分为分类任务和回归任务</p>
<h3 id="分类预测建模"><a href="#分类预测建模" class="headerlink" title="分类预测建模"></a>分类预测建模</h3><p>分类预测建模是逼近一个从输入变量（X）到离散的输出变量（y）之间的映射函数（f）</p>
<p>输出变量经常被称作标签或者类别。映射函数会对一个给定的观察样本预测一个类别标签</p>
<p>例如，一个文本邮件可以被归为两类：「垃圾邮件」，和「非垃圾邮件」</p>
<ul>
<li>分类问题需要把样本分为两类或者多类</li>
<li>分类的输入可以是实数也可以有离散变量</li>
<li>只有两个类别的分类问题经常被称作两类问题或者二元分类问题</li>
<li>具有多于两类的问题经常被称作多分类问题</li>
<li>样本属于多个类别的问题被称作多标签分类问题</li>
</ul>
<p>分类模型经常为输入样本预测得到与每一类别对应的像概率一样的连续值。这些概率可以被解释为样本属于每个类别的似然度或者置信度。预测到的概率可以通过选择概率最高的类别转换成类别标签</p>
<p>例如，某封邮件可能以 0.1 的概率被分为「垃圾邮件」，以 0.9 的概率被分为「非垃圾邮件」。因为非垃圾邮件的标签的概率最大，所以我们可以将概率转换成「非垃圾邮件」的标签</p>
<p>有很多用来衡量分类预测模型的性能的指标，但是分类准确率可能是最常用的一个</p>
<p>例如，如果一个分类预测模型做了 5 个预测，其中有 3 个是正确的，2 个这是错误的，那么这个模型的准确率就是 60%：</p>
<blockquote>
<p>accuracy = correct predictions / total predictions * 100<br>accuracy = 3 / 5 * 100<br>accuracy = 60%</p>
</blockquote>
<p>能够学习分类模型的算法就叫做分类算法</p>
<h3 id="回归预测模型"><a href="#回归预测模型" class="headerlink" title="回归预测模型"></a>回归预测模型</h3><p>回归预测建模是逼近一个从输入变量（X）到连续的输出变量（y）的函数映射</p>
<p>连续输出变量是一个实数，例如一个整数或者浮点数。这些变量通常是数量或者尺寸大小等等</p>
<p>例如，一座房子可能被预测到以 xx 美元出售，也许会在 $100,000 t 到$200,000 的范围内</p>
<ul>
<li>回归问题需要预测一个数量</li>
<li>回归的输入变量可以是连续的也可以是离散的</li>
<li>有多个输入变量的通常被称作多变量回归</li>
<li>输入变量是按照时间顺序的回归称为时间序列预测问题</li>
<li>因为回归预测问题预测的是一个数量，所以模型的性能可以用预测结果中的错误来评价</li>
</ul>
<p>有很多评价回归预测模型的方式，但是最常用的一个可能是计算误差值的均方根，即 RMSE</p>
<p>例如，如果回归预测模型做出了两个预测结果，一个是 1.5，对应的期望结果是 1.0；另一个是 3.3 对应的期望结果是 3.0. 那么，这两个回归预测的 RMSE 如下：</p>
<blockquote>
<p>RMSE = sqrt(average(error^2))<br>RMSE = sqrt(((1.0 - 1.5)^2 + (3.0 - 3.3)^2) / 2)<br>RMSE = sqrt((0.25 + 0.09) / 2)<br>RMSE = sqrt(0.17)<br>RMSE = 0.412</p>
</blockquote>
<p>使用 RMSE 的好处就是错误评分的单位与预测结果是一样的</p>
<p>一个能够学习回归预测模型的算法称作回归算法</p>
<p>有些算法的名字也有「regression,回归」一词，例如线性回归和 logistics 回归，这种情况有时候会让人迷惑因为线性回归确实是一个回归问题，但是 logistics 回归却是一个分类问题</p>
<h3 id="分类-vs-回归"><a href="#分类-vs-回归" class="headerlink" title="分类 vs 回归"></a>分类 vs 回归</h3><p>分类预测建模问题与回归预测建模问题是不一样的</p>
<ul>
<li>分类是预测一个离散标签的任务</li>
<li>回归是预测一个连续数量的任务</li>
</ul>
<p>分类和回归也有一些相同的地方：</p>
<ul>
<li>分类算法可能预测到一个连续的值，但是这些连续值对应的是一个类别的概率的形式</li>
<li>回归算法可以预测离散值，但是以整型量的形式预测离散值的</li>
</ul>
<p>有些算法既可以用来分类，也可以稍作修改就用来做回归问题，例如决策树和人工神经网络。但是一些算法就不行了——或者说是不太容易用于这两种类型的问题，例如线性回归是用来做回归预测建模的，logistics 回归是用来做分类预测建模的</p>
<p>重要的是，我们评价分类模型和预测模型的方式是不一样的，例如：</p>
<ul>
<li>分类预测可以使用准确率来评价，而回归问题则不能</li>
<li>回归预测可以使用均方根误差来评价，但是分类问题则不能</li>
</ul>
<h3 id="分类问题和回归问题之间的转换"><a href="#分类问题和回归问题之间的转换" class="headerlink" title="分类问题和回归问题之间的转换"></a>分类问题和回归问题之间的转换</h3><p>在一些情况中是可以将回归问题转换成分类问题的。例如，被预测的数量是可以被转换成离散数值的范围的</p>
<p>例如，在$0 到$100 之间的金额可以被分为两个区间：</p>
<ul>
<li>class 0：$0 到$49</li>
<li>class 1: $50 到$100</li>
</ul>
<p>这通常被称作离散化，结果中的输出变量是一个分类，分类的标签是有顺序的（称为叙序数）</p>
<p>在一些情况中，分类是可以转换成回归问题的。例如，一个标签可以被转换成一个连续的范围</p>
<p>一些算法早已通过为每一个类别预测一个概率，这个概率反过来又可以被扩展到一个特定的数值范围：</p>
<blockquote>
<p>quantity = min + probability * range</p>
</blockquote>
<p>与此对应，一个类别值也可以被序数化，并且映射到一个连续的范围中：</p>
<ul>
<li>$0 到 $49 是类别 1</li>
<li>$0 到 $49 是类别 2</li>
</ul>
<p>如果分类问题中的类别标签没有自然顺序的关系，那么从分类问题到回归问题的转换也许会导致奇怪的结果或者很差的性能，因为模型可能学到一个并不存在于从输入到连续输出之间的映射函数</p>
<p><em>原文链接</em><a href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" target="_blank" rel="noopener">https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/</a></p>
<h2 id="关于评价指标"><a href="#关于评价指标" class="headerlink" title="关于评价指标"></a>关于评价指标</h2><ul>
<li>评估指标即是我们对于一个模型效果的数值型量化。（有点类似与对于一个商品评价打分，而这是针对于模型效果和理想效果之间的一个打分）</li>
</ul>
<p>一般来说分类和回归问题的评价指标有如下一些形式：</p>
<h3 id="分类算法常见的评估指标如下："><a href="#分类算法常见的评估指标如下：" class="headerlink" title="分类算法常见的评估指标如下："></a>分类算法常见的评估指标如下：</h3><blockquote>
<ul>
<li>对于二类分类器/分类算法，评价指标主要有accuracy， Precision，Recall，F-score，Pr曲线，ROC-AUC曲线</li>
<li>对于多类分类器/分类算法，评价指标主要有accuracy， 宏平均和微平均，F-score</li>
</ul>
</blockquote>
<h3 id="对于回归预测类常见的评估指标如下"><a href="#对于回归预测类常见的评估指标如下" class="headerlink" title="对于回归预测类常见的评估指标如下:"></a>对于回归预测类常见的评估指标如下:</h3><blockquote>
<ul>
<li>平均绝对误差（Mean Absolute Error，MAE），均方误差（Mean Squared Error，MSE），平均绝对百分误差（Mean Absolute Percentage Error，MAPE），均方根误差（Root Mean Squared Error）， R2（R-Square）</li>
</ul>
</blockquote>
<h4 id="平均绝对误差"><a href="#平均绝对误差" class="headerlink" title="平均绝对误差"></a>平均绝对误差</h4><ul>
<li>平均绝对误差（Mean Absolute Error，MAE）:其能更好地反映预测值与真实值误差的实际情况，其计算公式如下：<br>$$MAE=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}_{i}\right|$$</li>
</ul>
<h3 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h3><ul>
<li>均方误差（Mean Squared Error，MSE）,均方误差,其计算公式为：<br>$$MSE=\frac{1}{N} \sum_{i}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2}$$</li>
</ul>
<h3 id="R2（R-Square）"><a href="#R2（R-Square）" class="headerlink" title="R2（R-Square）"></a>R2（R-Square）</h3><ul>
<li>残差平方和:<br>$$SS_{res}=\sum\left(y_{i}-\hat{y}_{i}\right)^{2}$$</li>
<li>总平均值:<br>$$SS_{tot}=\sum\left(y_{i}-\overline{y}_{i}\right)^{2}$$</li>
<li>其中$\overline{y}$表示$y$的平均值得到$R^2$的表达式为:</li>
</ul>
<p>$$R^{2}=1-\frac{SS_{res}}{SS_{tot}}$$</p>
<p>$R^2$用于度量因变量的变异中可由自变量解释部分所占的比例，取值范围是 0~1，$R^2$越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。所以$R^2$也称为拟合优度（Goodness of Fit）的统计量</p>
<p>$y_{i}$表示真实值,</p>
<p>$\hat{y}_{i}$表示预测值,</p>
<p>$\overline{y}_{i}$表示样本均值。得分越高拟合效果越好</p>
<h3 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h3><p><img src="https://s1.ax1x.com/2020/03/21/8hqPgA.png" alt=""><br>上图红色点是incoming自变量与Consuming因变量对应的散点图，蓝色线是回归方程线（最小二乘法得到）；<br>这里红色点$y_{i}$表示一个响应观测值点（共4个），蓝色点$f_{i}$是响应观测值对应的回归曲线上的点，两个的差值就是残差，残差值共有4个,$\overline{y}$是响应变量的平均值。</p>
<p>根据平方和分解公式:<br><img src="https://s1.ax1x.com/2020/03/21/8hquCQ.jpg" alt=""><br>即：SS 总体=SS 回归 + SS 残差 (观测值与平均值的差值平方和被残差平方和以及回归差值平方和之和解释)</p>
<h1 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h1><ol>
<li>此题为传统的数据挖掘问题，通过数据科学以及机器学习深度学习的办法来进行建模得到结果。</li>
<li>此题是一个典型的回归问题。</li>
<li>主要应用xgb、lgb、catboost，以及pandas、numpy、matplotlib、seabon、sklearn、keras等等数据挖掘常用库或者框架来进行数据挖掘任务。</li>
<li>通过EDA来挖掘数据的联系和自我熟悉数据</li>
</ol>
<h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 1) 载入训练集和测试集</span><br><span class="line">Train_data &#x3D; pd.read_csv(&#39;.&#x2F;datalab&#x2F;used_car_train_20200313.csv&#39;,sep&#x3D;(&#39; &#39;))</span><br><span class="line">Test_data &#x3D; pd.read_csv(&#39;.&#x2F;datalab&#x2F;used_car_testA_20200313.csv&#39;,sep&#x3D;(&#39; &#39;))</span><br><span class="line"></span><br><span class="line">print(Train_data.shape) # 返回行,列数</span><br><span class="line">print(Test_data.shape)</span><br><span class="line">out_put &#x3D; Train_data.head(4) # 返回前四行字段数据</span><br><span class="line">print(out_put)</span><br><span class="line"></span><br><span class="line"># 2)分类指标评价计算</span><br><span class="line"></span><br><span class="line">## accuracy</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">y_pred &#x3D; [0, 1, 0, 1] # 预测标签</span><br><span class="line">y_true &#x3D; [0, 1, 1, 1] # 正确标签</span><br><span class="line">print(&#39;ACC:&#39;,accuracy_score(y_true, y_pred)) # 返回正确样本所占比例（float）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">TP：真正例：即将正样本预测为正样本</span><br><span class="line">TN：真反例：即将负样本预测为负样本</span><br><span class="line">FP：假正例：将负样本预测为了正样本</span><br><span class="line">FN：假反例：将正样本预测为了负样本</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">## Percision,Recall,F1-score</span><br><span class="line">from sklearn import metrics</span><br><span class="line">y_pred &#x3D; [0, 1, 0, 0]</span><br><span class="line">y_true &#x3D; [0, 1, 0, 1]</span><br><span class="line">print(&#39;Precision&#39;,metrics.precision_score(y_true, y_pred)) # 返回 TP &#x2F; (TP + FP)</span><br><span class="line">print(&#39;Recall&#39;,metrics.recall_score(y_true, y_pred)) # 返回 TP &#x2F; (TP + FN)</span><br><span class="line">print(&#39;F1-score:&#39;,metrics.f1_score(y_true, y_pred)) # 返回 2*(P*R)&#x2F;(P+R)</span><br><span class="line"></span><br><span class="line">## AUC</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">y_true &#x3D; np.array([0, 0, 1, 1]) # True labels or binary label indicators</span><br><span class="line">y_scores &#x3D; np.array([0.1, 0.4, 0.35, 0.8]) # Target scores</span><br><span class="line">print(&#39;AUC socre:&#39;,roc_auc_score(y_true, y_scores))</span><br><span class="line"></span><br><span class="line"># coding&#x3D;utf-8</span><br><span class="line"># import numpy as np</span><br><span class="line"># from sklearn import metrics</span><br><span class="line"></span><br><span class="line"># MAPE需要自己实现</span><br><span class="line">def mape(y_true, y_pred):</span><br><span class="line">    return np.mean(np.abs((y_pred - y_true) &#x2F; y_true))</span><br><span class="line"></span><br><span class="line">y_true &#x3D; np.array([1.0, 5.0, 4.0, 3.0, 2.0, 5.0, -3.0])</span><br><span class="line">y_pred &#x3D; np.array([1.0, 4.5, 3.8, 3.2, 3.0, 4.8, -2.2])</span><br><span class="line"></span><br><span class="line"># MSE</span><br><span class="line">print(&#39;MSE:&#39;,metrics.mean_squared_error(y_true, y_pred))</span><br><span class="line"># RMSE</span><br><span class="line">print(&#39;RMSE:&#39;,np.sqrt(metrics.mean_squared_error(y_true, y_pred)))</span><br><span class="line"># MAE</span><br><span class="line">print(&#39;MAE:&#39;,metrics.mean_absolute_error(y_true, y_pred))</span><br><span class="line"># MAPE</span><br><span class="line">print(&#39;MAPE:&#39;,mape(y_true, y_pred))</span><br><span class="line"></span><br><span class="line">## R2-score</span><br><span class="line">from sklearn.metrics import r2_score</span><br><span class="line">y_true &#x3D; [3, -0.5, 2, 7]</span><br><span class="line">y_pred &#x3D; [2.5, 0.0, 2, 8]</span><br><span class="line">print(&#39;R2-score:&#39;,r2_score(y_true, y_pred))</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://happybear1234.github.io/2020/03/19/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8github%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="happybear">
      <meta itemprop="description" content="happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="happybear">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/19/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8github%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/" class="post-title-link" itemprop="url">如何使用github创建博客</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-19 21:52:03" itemprop="dateCreated datePublished" datetime="2020-03-19T21:52:03+08:00">2020-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-21 12:05:36" itemprop="dateModified" datetime="2020-03-21T12:05:36+08:00">2020-03-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-users"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="firestore-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>990</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>-利用 Github 搭建博客需要熟悉git方便管理.操作<a href="http://iissnan.com/progit/" target="_blank" rel="noopener">如果对git感兴趣请参考</a></p>
<h1 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h1><h2 id="安装-node"><a href="#安装-node" class="headerlink" title="安装 node"></a>安装 node</h2><ul>
<li>因为 hexo 是基于 node 框架的,先下载安装 node ,查看<code>node -v</code>版本,没有的话就根据提示操作</li>
</ul>
<h2 id="安装-npm"><a href="#安装-npm" class="headerlink" title="安装 npm"></a>安装 npm</h2><ul>
<li>安装 nodejs 肯定要安装 npm ,Ubuntu下载可能会很慢,建议换成国内源,参考<a href="https://www.cnblogs.com/vipstone/p/9038023.html" target="_blank" rel="noopener">Ubuntu apt-get和pip源更换</a></li>
</ul>
<h2 id="初始化-blog"><a href="#初始化-blog" class="headerlink" title="初始化 blog"></a>初始化 blog</h2><ol>
<li>安装 hexo ,在 终端 中输入:<code>npm install hexo-cli -g</code>(<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">参考Hexo文档</a>)</li>
<li>初始化 blog 目录:<code>hexo init happybear1234.github.io</code>(这里的 happybear1234 换成你自己的英文名,我这里就是github的用户名)</li>
<li>初始化之后,进入到 blog 目录下:<code>cd happybear1234.github.io</code>(以后对博客的所以操作都是在这)</li>
<li>安装<code>npm install</code></li>
<li>clean一下:<code>hexo clean</code></li>
<li>生成静态页面:<code>hexo g</code></li>
<li>运行起来:<code>hexo s</code></li>
</ol>
<ul>
<li>打开浏览器,输入 终端 里网址 localhost:4000 就能看到了(如果提示服务端口被占用,可以换个端口,<code>hexo server -p 5000</code>)</li>
</ul>
<h1 id="选一个Hexo主题"><a href="#选一个Hexo主题" class="headerlink" title="选一个Hexo主题"></a>选一个Hexo主题</h1><ul>
<li>这里提供<a href="https://www.zhihu.com/question/24422335" target="_blank" rel="noopener">知乎答主们推荐的hexo主题大全</a>,刚开始为了熟悉各种配置建议使用 NexT 主题,因为文档比较详细,界面也很简洁,如果安装 NexT 主题和配置可以参考<a href="https://theme-next.org/docs/getting-started/" target="_blank" rel="noopener">文档</a></li>
</ul>
<h1 id="部署到网上"><a href="#部署到网上" class="headerlink" title="部署到网上"></a>部署到网上</h1><ul>
<li>现在的 blog 只能自己本地访问,可以使用 Github Pages 免费部署</li>
</ul>
<h2 id="创建仓库"><a href="#创建仓库" class="headerlink" title="创建仓库"></a>创建仓库</h2><ul>
<li>创建一个 xxx.github.io 的 public 仓库,这里 xxx 写你的名字,我这里写的 happybear1234.github.io,那么之后我就可以用 happybear1234.github.io 来访问了</li>
</ul>
<h2 id="安装-hexo-deployer-git"><a href="#安装-hexo-deployer-git" class="headerlink" title="安装 hexo-deployer-git"></a>安装 hexo-deployer-git</h2><ul>
<li>在 blog 目录下输入下面命令,这样本地的文章才能 push 到 Github 上面去<br>  <code>npm install hexo-deployer-git --save</code></li>
</ul>
<h2 id="配置Git"><a href="#配置Git" class="headerlink" title="配置Git"></a>配置Git</h2><ul>
<li><p>打开 blog 目录下配置文件:<code>vi _config.yml</code>,输入你的 git 地址:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  	    type: git</span><br><span class="line">  	    repo: https:&#x2F;&#x2F;github.com&#x2F;xxx&#x2F;xxxx.github.io.git</span><br></pre></td></tr></table></figure>
<h2 id="推送网站到-Github-上"><a href="#推送网站到-Github-上" class="headerlink" title="推送网站到 Github 上"></a>推送网站到 Github 上</h2></li>
<li><p>直接在 blog 目录下输入:<code>hexo d</code></p>
</li>
<li><p>push 上去以后你就可以输入 xxx.github.io 进行访问啦</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">happybear</p>
  <div class="site-description" itemprop="description">happybear的个人博客,主要涉及到编程(C++,Python,Linux),个人提升学习</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/happybear1234" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;happybear1234" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">happybear</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">45k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">41 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.2
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>




  <script src="https://www.gstatic.com/firebasejs/6.3.3/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/6.3.3/firebase-firestore.js"></script>
  <script>
    firebase.initializeApp({
      apiKey   : '',
      projectId: ''
    });

    function getCount(doc, increaseCount) {
      // IncreaseCount will be false when not in article page
      return doc.get().then(d => {
        var count = 0;
        if (!d.exists) { // Has no data, initialize count
          if (increaseCount) {
            doc.set({
              count: 1
            });
            count = 1;
          }
        } else { // Has data
          count = d.data().count;
          if (increaseCount) {
            // If first view this article
            doc.set({ // Increase count
              count: count + 1
            });
            count++;
          }
        }

        return count;
      });
    }

    function appendCountTo(el) {
      return count => {
        el.innerText = count;
      }
    }
  </script>
  <script>
    (function() {
      var db = firebase.firestore();
      var articles = db.collection('articles');

      if (CONFIG.page.isPost) { // Is article page
        var title = document.querySelector('.post-title').innerText.trim();
        var doc = articles.doc(title);
        var increaseCount = CONFIG.hostname === location.hostname;
        if (localStorage.getItem(title)) {
          increaseCount = false;
        } else {
          // Mark as visited
          localStorage.setItem(title, true);
        }
        getCount(doc, increaseCount).then(appendCountTo(document.querySelector('.firestore-visitors-count')));
      } else if (CONFIG.page.isHome) { // Is index page
        var promises = [...document.querySelectorAll('.post-title')].map(element => {
          var title = element.innerText.trim();
          var doc = articles.doc(title);
          return getCount(doc);
        });
        Promise.all(promises).then(counts => {
          var metas = document.querySelectorAll('.firestore-visitors-count');
          counts.forEach((val, idx) => {
            appendCountTo(metas[idx])(val);
          });
        });
      }
    })();
  </script>




      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
